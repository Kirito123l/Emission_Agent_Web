"""APIè·¯ç”±"""
import os
import json
import tempfile
import pandas as pd
import logging
import sys
import asyncio
import uuid
from pathlib import Path
from datetime import datetime
from fastapi import APIRouter, HTTPException, UploadFile, File, Form, Request, Query
from fastapi.responses import FileResponse, StreamingResponse
from typing import Optional, Dict, Any
from urllib.parse import quote

from .models import (
    ChatRequest, ChatResponse, FilePreviewResponse,
    SessionInfo, SessionListResponse, HistoryResponse, UpdateSessionTitleRequest
)


from .session import SessionRegistry


def get_user_id(request: Request) -> str:
    """Extract user_id from X-User-ID header, fall back to 'default'."""
    return (request.headers.get("X-User-ID") or "default").strip() or "default"

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# ç¡®ä¿æœ‰handler
if not logger.handlers:
    handler = logging.StreamHandler(sys.stdout)
    handler.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

router = APIRouter()

# ä¸´æ—¶æ–‡ä»¶ç›®å½•
TEMP_DIR = Path(tempfile.gettempdir()) / "emission_agent"
TEMP_DIR.mkdir(exist_ok=True)


def friendly_error_message(error: Exception) -> str:
    """Convert low-level exceptions to user-friendly actionable messages."""
    text = str(error)
    lower = text.lower()

    connection_signals = [
        "connection error",
        "connecterror",
        "unexpected eof",
        "ssl",
        "tls",
        "timed out",
        "api_connection_error",
    ]
    if any(sig in lower for sig in connection_signals):
        return (
            "ä¸Šæ¸¸å¤§æ¨¡å‹è¿æ¥å¤±è´¥ï¼ˆç½‘ç»œ/ä»£ç†å¼‚å¸¸ï¼‰ã€‚è¯·ç¨åé‡è¯•ã€‚\n"
            "è‹¥é—®é¢˜æŒç»­ï¼šè¯·æ£€æŸ¥ HTTP(S)_PROXY é…ç½®ã€ä»£ç†æœåŠ¡è¿é€šæ€§ï¼Œ"
            "æˆ–æš‚æ—¶å…³é—­ä»£ç†åé‡è¯•ã€‚"
        )

    return f"å¤„ç†å‡ºé”™: {text}"

def clean_reply_text(reply: str) -> str:
    """æ¸…ç†å›å¤æ–‡æœ¬ï¼Œç§»é™¤JSONç­‰æŠ€æœ¯å†…å®¹"""
    import re

    # ç§»é™¤JSONä»£ç å—
    reply = re.sub(r'```json[\s\S]*?```', '', reply)
    reply = re.sub(r'```[\s\S]*?```', '', reply)

    # ç§»é™¤å¤§å—JSONï¼ˆåŒ…å«curveæˆ–pollutantsçš„ï¼‰
    reply = re.sub(r'\{[^{}]*"curve"[^{}]*\}', '', reply)
    reply = re.sub(r'\{[^{}]*"pollutants"[^{}]*\}', '', reply)

    # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
    reply = re.sub(r'\n\s*\n\s*\n', '\n\n', reply)

    return reply.strip()


def normalize_download_file(
    download_file: Optional[Any],
    session_id: str,
    message_id: Optional[str] = None,
    user_id: Optional[str] = None
) -> Optional[Dict[str, Any]]:
    """Normalize download metadata to a stable frontend-friendly shape."""
    if not download_file:
        return None

    path: Optional[str] = None
    filename: Optional[str] = None

    if isinstance(download_file, dict):
        path = download_file.get("path")
        filename = download_file.get("filename")
    elif isinstance(download_file, str):
        path = download_file
        filename = Path(download_file).name if download_file else None

    if not filename and path:
        filename = Path(path).name
    if not path and not filename:
        return None

    normalized: Dict[str, Any] = {
        "path": str(path) if path else None,
        "filename": filename,
        "file_id": session_id,
    }
    uid_qs = f"?user_id={quote(user_id)}" if user_id else ""
    if message_id:
        normalized["message_id"] = message_id
        normalized["url"] = f"/api/file/download/message/{session_id}/{message_id}{uid_qs}"
    elif filename:
        normalized["url"] = f"/api/download/{quote(filename)}{uid_qs}"
    return normalized


def attach_download_to_table_data(
    table_data: Optional[Dict[str, Any]],
    download_file: Optional[Dict[str, Any]]
) -> Optional[Dict[str, Any]]:
    """Attach download metadata to table payload so history rendering can keep download buttons."""
    if not table_data or not isinstance(table_data, dict):
        return table_data
    if not download_file:
        return table_data

    enriched = dict(table_data)

    if not enriched.get("download"):
        url = download_file.get("url")
        filename = download_file.get("filename")
        if url and filename:
            enriched["download"] = {"url": url, "filename": filename}

    if not enriched.get("file_id") and download_file.get("file_id"):
        enriched["file_id"] = download_file["file_id"]

    return enriched


def build_emission_chart_data(skill_name: Optional[str], data: Dict) -> Optional[Dict]:
    """Normalize emission-factor results for frontend chart rendering. æ”¯æŒå¤šç§æ ¼å¼ã€‚"""
    if not skill_name or not isinstance(data, dict):
        return None

    # æ ¼å¼1: æ ‡å‡†æ ¼å¼ (æœ‰ speed_curve + query_summary)
    if "speed_curve" in data and "query_summary" in data:
        query_summary = data.get("query_summary", {})
        vehicle_type = query_summary.get("vehicle_type", "Unknown")
        model_year = query_summary.get("model_year", 2020)
        pollutant = query_summary.get("pollutant", "NOx")
        speed_curve = data.get("speed_curve", [])

        return {
            "type": "emission_factors",
            "vehicle_type": vehicle_type,
            "model_year": model_year,
            "pollutants": {
                pollutant: {
                    "curve": speed_curve,
                    "unit": data.get("unit", "g/mile")
                }
            },
            "metadata": {
                "data_source": data.get("data_source", ""),
                "speed_range": data.get("speed_range", {}),
                "data_points": data.get("data_points", 0)
            },
            "key_points": extract_key_points({"pollutant": pollutant, "curve": speed_curve})
        }

    # æ ¼å¼2: å¤šæ±¡æŸ“ç‰©æ ¼å¼ (åªæœ‰ pollutants)
    if skill_name == "query_emission_factors" and "pollutants" in data:
        pollutants_data = data.get("pollutants", {})
        if isinstance(pollutants_data, dict):
            # æ ‡å‡†åŒ–æ¯ä¸ªæ±¡æŸ“ç‰©çš„æ•°æ®æ ¼å¼ï¼šå°† speed_curve è½¬æ¢ä¸º curve
            normalized_pollutants = {}
            for pollutant, poll_data in pollutants_data.items():
                if isinstance(poll_data, dict):
                    # å¦‚æœæœ‰ speed_curve ä½†æ²¡æœ‰ curveï¼Œè¿›è¡Œè½¬æ¢
                    if "speed_curve" in poll_data and "curve" not in poll_data:
                        # è½¬æ¢ speed_curve ä¸º curve æ ¼å¼ï¼ˆg/mile -> g/kmï¼‰
                        speed_curve = poll_data.get("speed_curve", [])
                        curve = []
                        for point in speed_curve:
                            curve.append({
                                "speed_kph": point.get("speed_kph", 0),
                                "emission_rate": round(point.get("emission_rate", 0) / 1.60934, 4)  # g/mile -> g/km
                            })
                        normalized_pollutants[pollutant] = {
                            "curve": curve,
                            "unit": "g/km"
                        }
                    else:
                        # å·²ç»æ˜¯æ­£ç¡®æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                        normalized_pollutants[pollutant] = poll_data

            return {
                "type": "emission_factors",
                "vehicle_type": data.get("vehicle_type", "Unknown"),
                "model_year": data.get("model_year", 2020),
                "pollutants": normalized_pollutants,
                "metadata": data.get("metadata", {}),
                "key_points": extract_key_points(normalized_pollutants)
            }

    # æ ¼å¼3: åµŒå¥—åœ¨ data å­—æ®µä¸­
    if "data" in data and isinstance(data["data"], dict):
        return build_emission_chart_data(skill_name, data["data"])

    # æ ¼å¼4: ç›´æ¥æ˜¯æ›²çº¿æ•°æ®
    if "curve" in data or "emission_curve" in data:
        curve = data.get("curve") or data.get("emission_curve", [])
        return {
            "type": "emission_factors",
            "vehicle_type": data.get("vehicle_type", "Unknown"),
            "model_year": data.get("model_year", 2020),
            "pollutants": {
                "default": {"curve": curve, "unit": "g/km"}
            },
            "metadata": {},
            "key_points": extract_key_points({"default": {"curve": curve}})
        }

    logger.warning(f"æ— æ³•è¯†åˆ«çš„å›¾è¡¨æ•°æ®æ ¼å¼: {list(data.keys())}")
    return None


def extract_key_points(pollutants_data) -> list:
    """Extract key speed points (30/60/90 km/h) for table display."""
    if not pollutants_data:
        return []

    # New format: {"pollutant": name, "curve": [...]}
    if isinstance(pollutants_data, dict) and "curve" in pollutants_data:
        pollutant = pollutants_data.get("pollutant", "Unknown")
        curve = pollutants_data.get("curve", [])
        return _pick_key_points(curve, pollutant)

    # Legacy format: {"NOx": {"curve": [...]}, ...}
    if isinstance(pollutants_data, dict):
        for pollutant, info in pollutants_data.items():
            curve = info.get("curve", []) if isinstance(info, dict) else []
            if curve:
                return _pick_key_points(curve, pollutant)

    return []

def _pick_key_points(curve, pollutant: str) -> list:
    if not curve:
        return []
    targets = [30, 60, 90]
    labels = ["City Congestion", "City Cruise", "Highway"]
    points = []
    for target, label in zip(targets, labels):
        closest = min(curve, key=lambda p: abs(p.get("speed_kph", 0) - target))
        points.append({
            "speed": closest.get("speed_kph"),
            "rate": closest.get("emission_rate"),
            "label": label,
            "pollutant": pollutant
        })
    return points

@router.post("/chat", response_model=ChatResponse)
async def chat(
    request: Request,
    message: str = Form(...),
    session_id: Optional[str] = Form(None),
    file: Optional[UploadFile] = File(None)
):
    """
    å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤

    æ”¯æŒï¼š
    - çº¯æ–‡æœ¬æ¶ˆæ¯
    - å¸¦Excelæ–‡ä»¶çš„æ¶ˆæ¯ï¼ˆç”¨äºè½¨è¿¹è®¡ç®—æˆ–è·¯æ®µè®¡ç®—ï¼‰
    """
    import sys
    sys.stdout.write(f"\n{'='*60}\n")
    sys.stdout.write("ğŸ”µ æ”¶åˆ°èŠå¤©è¯·æ±‚\n")
    sys.stdout.write(f"ğŸ“ æ¶ˆæ¯: {message[:100]}...\n")
    sys.stdout.write(f"ğŸ†” ä¼šè¯ID: {session_id}\n")
    sys.stdout.write(f"ğŸ“ æ–‡ä»¶: {file.filename if file else 'None'}\n")
    sys.stdout.write(f"{'='*60}\n")
    sys.stdout.flush()

    try:
        # è·å–æˆ–åˆ›å»ºä¼šè¯
        user_id = get_user_id(request)
        mgr = SessionRegistry.get(user_id)
        session = mgr.get_or_create_session(session_id)

        # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
        input_file_path = None
        output_file_path = None

        if file:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            suffix = Path(file.filename).suffix
            input_file_path = TEMP_DIR / f"{session.session_id}_input{suffix}"
            with open(input_file_path, "wb") as f:
                content = await file.read()
                f.write(content)

            # å‡†å¤‡è¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_file_path = TEMP_DIR / f"{session.session_id}_output.xlsx"

            # åœ¨æ¶ˆæ¯ä¸­æ·»åŠ æ–‡ä»¶ä¿¡æ¯ - ä½¿ç”¨æ˜ç¡®çš„æ ¼å¼è®©Agentè¯†åˆ«
            message = f"{message}\n\næ–‡ä»¶å·²ä¸Šä¼ ï¼Œè·¯å¾„: {str(input_file_path)}\nè¯·ä½¿ç”¨ input_file å‚æ•°å¤„ç†æ­¤æ–‡ä»¶ã€‚"

        # è°ƒç”¨Routerå¤„ç†æ¶ˆæ¯
        logger.info(f"è°ƒç”¨Routerå¤„ç†æ¶ˆæ¯...")
        result = await session.chat(message, input_file_path)
        logger.info(f"Routerå›å¤: {result['text'][:100] if result['text'] else 'None'}...")

        # æ›´æ–°ä¼šè¯ä¿¡æ¯
        session.message_count += 1
        session.updated_at = datetime.now().isoformat()
        mgr.update_session_title(session.session_id, message)

        # ä»RouterResponseæå–æ•°æ®
        reply_text = result.get("text", "")
        chart_data = result.get("chart_data")
        table_data = result.get("table_data")
        assistant_message_id = uuid.uuid4().hex[:12]
        download_file = normalize_download_file(
            result.get("download_file"),
            session.session_id,
            assistant_message_id,
            user_id
        )

        logger.info(f"[DEBUG API] download_file from router: {download_file}")
        logger.info(f"[DEBUG API] download_file type: {type(download_file)}")
        logger.info(f"[DEBUG API] download_file bool: {bool(download_file)}")

        # ç¡®å®šæ•°æ®ç±»å‹
        data_type = None
        if chart_data:
            data_type = "chart"
        elif table_data:
            data_type = "table"

        # å°†ä¸‹è½½ä¿¡æ¯ç»‘å®šåˆ°è¡¨æ ¼æ•°æ®ï¼Œç¡®ä¿å†å²æ¶ˆæ¯ä¹Ÿèƒ½æ¸²æŸ“ä¸‹è½½æŒ‰é’®
        table_data = attach_download_to_table_data(table_data, download_file)

        # å¦‚æœæœ‰ä¸‹è½½æ–‡ä»¶ï¼Œæ›´æ–°session
        if download_file:
            session.last_result_file = download_file

        # æ„å»ºå“åº”
        response = ChatResponse(
            reply=clean_reply_text(reply_text),
            session_id=session.session_id,
            success=True,
            data_type=data_type,
            chart_data=chart_data,
            table_data=table_data,
            file_id=session.session_id if download_file else None,
            download_file=download_file,
            message_id=assistant_message_id
        )

        # ä¿å­˜å¯¹è¯å†å²åˆ°Session
        session.save_turn(
            user_input=message,
            assistant_response=reply_text,
            chart_data=chart_data,
            table_data=table_data,
            data_type=data_type,
            file_id=session.session_id if download_file else None,  # æ·»åŠ  file_id
            download_file=download_file,
            message_id=assistant_message_id
        )

        mgr.save_session()

        logger.info(f"=== è¯·æ±‚å¤„ç†å®Œæˆ ===")
        return response

    except Exception as e:
        logger.error(f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}", exc_info=True)

        return ChatResponse(
            reply=f"æŠ±æ­‰ï¼Œ{friendly_error_message(e)}",
            session_id=session_id or "",
            success=False,
            error=str(e)
        )

@router.post("/chat/stream")
async def chat_stream(
    request: Request,
    message: str = Form(...),
    session_id: Optional[str] = Form(None),
    file: Optional[UploadFile] = File(None)
):
    """
    æµå¼èŠå¤©æ¥å£ - å®æ—¶è¿”å›å“åº”

    æ”¯æŒï¼š
    - å®æ—¶çŠ¶æ€æ›´æ–°
    - é€æ­¥æ–‡æœ¬è¾“å‡º
    - å›¾è¡¨å’Œè¡¨æ ¼æ•°æ®
    """
    user_id = get_user_id(request)
    mgr = SessionRegistry.get(user_id)

    async def generate():
        try:
            # 1. å‘é€"æ€è€ƒä¸­"çŠ¶æ€
            yield json.dumps({
                "type": "status",
                "content": "æ­£åœ¨ç†è§£æ‚¨çš„é—®é¢˜..."
            }, ensure_ascii=False) + "\n"
            await asyncio.sleep(0.1)

            # 2. è·å–æˆ–åˆ›å»ºä¼šè¯
            session = mgr.get_or_create_session(session_id)

            # 3. å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
            input_file_path = None
            output_file_path = None

            if file:
                yield json.dumps({
                    "type": "status",
                    "content": "æ­£åœ¨å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶..."
                }, ensure_ascii=False) + "\n"
                await asyncio.sleep(0.1)

                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
                suffix = Path(file.filename).suffix
                input_file_path = TEMP_DIR / f"{session.session_id}_input{suffix}"
                with open(input_file_path, "wb") as f:
                    content = await file.read()
                    f.write(content)

                # å‡†å¤‡è¾“å‡ºæ–‡ä»¶è·¯å¾„
                output_file_path = TEMP_DIR / f"{session.session_id}_output.xlsx"

                # åœ¨æ¶ˆæ¯ä¸­æ·»åŠ æ–‡ä»¶ä¿¡æ¯
                message_with_file = f"{message}\n\næ–‡ä»¶å·²ä¸Šä¼ ï¼Œè·¯å¾„: {str(input_file_path)}\nè¯·ä½¿ç”¨ input_file å‚æ•°å¤„ç†æ­¤æ–‡ä»¶ã€‚"
            else:
                message_with_file = message

            # 4. Planningé˜¶æ®µ
            yield json.dumps({
                "type": "status",
                "content": "æ­£åœ¨åˆ†æä»»åŠ¡..."
            }, ensure_ascii=False) + "\n"
            await asyncio.sleep(0.1)

            # 5. è°ƒç”¨Routerå¤„ç†ï¼ˆå¸¦å¿ƒè·³ä¿æ´»ï¼‰
            heartbeat_msg = json.dumps({"type": "heartbeat"}, ensure_ascii=False) + "\n"
            chat_task = asyncio.create_task(session.chat(message_with_file, input_file_path))
            while not chat_task.done():
                try:
                    result = await asyncio.wait_for(asyncio.shield(chat_task), timeout=15)
                    break
                except asyncio.TimeoutError:
                    yield heartbeat_msg
            else:
                result = chat_task.result()

            # 6. æµå¼è¾“å‡ºæœ€ç»ˆæ–‡æœ¬
            reply_text = result.get("text", "")
            reply_text_clean = clean_reply_text(reply_text)
            chunk_size = 20  # æ¯æ¬¡å‘é€20ä¸ªå­—ç¬¦

            for i in range(0, len(reply_text_clean), chunk_size):
                chunk = reply_text_clean[i:i+chunk_size]
                yield json.dumps({
                    "type": "text",
                    "content": chunk
                }, ensure_ascii=False) + "\n"
                await asyncio.sleep(0.05)  # æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ

            # 7. å¤„ç†å›¾è¡¨/è¡¨æ ¼æ•°æ®ï¼ˆä»RouterResponseç›´æ¥è·å–ï¼‰
            chart_data = result.get("chart_data")
            table_data = result.get("table_data")
            assistant_message_id = uuid.uuid4().hex[:12]
            download_file = normalize_download_file(
                result.get("download_file"),
                session.session_id,
                assistant_message_id,
                user_id
            )

            logger.info(f"[DEBUG STREAM] download_file from router: {download_file}")
            logger.info(f"[DEBUG STREAM] download_file type: {type(download_file)}")
            logger.info(f"[DEBUG STREAM] download_file bool: {bool(download_file)}")

            # ç¡®å®šæ•°æ®ç±»å‹ï¼ˆä¼˜å…ˆçº§ï¼šchart > tableï¼‰
            data_type = None
            if chart_data:
                data_type = "chart"
                yield json.dumps({
                    "type": "chart",
                    "content": chart_data
                }, ensure_ascii=False) + "\n"

            # ç‹¬ç«‹å‘é€è¡¨æ ¼æ•°æ®ï¼ˆå¯ä»¥ä¸å›¾è¡¨å…±å­˜ï¼‰
            if table_data:
                if not data_type:  # å¦‚æœæ²¡æœ‰å›¾è¡¨ï¼Œè®¾ç½® data_type ä¸º table
                    data_type = "table"
                table_data = attach_download_to_table_data(table_data, download_file)
                yield json.dumps({
                    "type": "table",
                    "content": table_data
                }, ensure_ascii=False) + "\n"

            # å¦‚æœæœ‰ä¸‹è½½æ–‡ä»¶ï¼Œæ›´æ–°session
            if download_file:
                session.last_result_file = download_file

            # 8. æ›´æ–°ä¼šè¯ä¿¡æ¯
            session.message_count += 1
            session.updated_at = datetime.now().isoformat()
            mgr.update_session_title(session.session_id, message)

            # 9. ä¿å­˜å¯¹è¯å†å²
            session.save_turn(
                user_input=message,
                assistant_response=reply_text,
                chart_data=chart_data,
                table_data=table_data,
                data_type=data_type,
                file_id=session.session_id if download_file else None,  # æ·»åŠ  file_id
                download_file=download_file,
                message_id=assistant_message_id
            )
            mgr.save_session()

            # 10. å‘é€å®Œæˆä¿¡å·
            yield json.dumps({
                "type": "done",
                "session_id": session.session_id,
                "file_id": session.session_id if download_file else None,
                "download_file": download_file,
                "message_id": assistant_message_id
            }, ensure_ascii=False) + "\n"

        except Exception as e:
            logger.error(f"æµå¼å¤„ç†å‡ºé”™: {str(e)}", exc_info=True)
            yield json.dumps({
                "type": "error",
                "content": friendly_error_message(e)
            }, ensure_ascii=False) + "\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # ç¦ç”¨nginxç¼“å†²
        }
    )

@router.post("/file/preview", response_model=FilePreviewResponse)
async def preview_file(file: UploadFile = File(...)):
    """
    é¢„è§ˆä¸Šä¼ çš„Excelæ–‡ä»¶ï¼ˆå‰5è¡Œï¼‰

    ç”¨äºåœ¨å‘é€å‰è®©ç”¨æˆ·ç¡®è®¤æ–‡ä»¶å†…å®¹
    """
    logger.info(f"=== æ–‡ä»¶é¢„è§ˆè¯·æ±‚ ===")
    logger.info(f"æ–‡ä»¶å: {file.filename}")

    try:
        # è¯»å–æ–‡ä»¶
        content = await file.read()

        # æ ¹æ®æ–‡ä»¶ç±»å‹è¯»å–
        suffix = Path(file.filename).suffix.lower()
        if suffix == ".csv":
            df = pd.read_csv(pd.io.common.BytesIO(content))
        else:
            df = pd.read_excel(pd.io.common.BytesIO(content))

        # æ£€æµ‹æ–‡ä»¶ç±»å‹
        columns_lower = [c.lower() for c in df.columns]

        if any("speed" in c or "é€Ÿåº¦" in c or "è½¦é€Ÿ" in c for c in columns_lower):
            detected_type = "trajectory"
            warnings = []
            if not any("acc" in c or "åŠ é€Ÿåº¦" in c for c in columns_lower):
                warnings.append("æœªæ‰¾åˆ°åŠ é€Ÿåº¦åˆ—ï¼Œå°†è‡ªåŠ¨è®¡ç®—")
            if not any("grade" in c or "å¡åº¦" in c for c in columns_lower):
                warnings.append("æœªæ‰¾åˆ°å¡åº¦åˆ—ï¼Œé»˜è®¤ä½¿ç”¨0%")
        elif any("length" in c or "é•¿åº¦" in c for c in columns_lower):
            detected_type = "links"
            warnings = []
        else:
            detected_type = "unknown"
            warnings = ["æ— æ³•è¯†åˆ«æ–‡ä»¶ç±»å‹"]

        return FilePreviewResponse(
            filename=file.filename,
            size_kb=len(content) / 1024,
            rows_total=len(df),
            columns=list(df.columns),
            preview_rows=df.head(5).to_dict(orient="records"),
            detected_type=detected_type,
            warnings=warnings
        )

    except Exception as e:
        raise HTTPException(status_code=400, detail=f"æ–‡ä»¶è§£æå¤±è´¥: {str(e)}")

@router.get("/file/download/{file_id}")
async def download_file(file_id: str, request: Request, user_id: Optional[str] = Query(None)):
    """ä¸‹è½½ç»“æœæ–‡ä»¶"""
    uid = user_id or get_user_id(request)
    session = SessionRegistry.get(uid).get_session(file_id)
    if not session or not session.last_result_file:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    # å¤„ç†ä¸¤ç§æ ¼å¼ï¼šdict (æ–°æ ¼å¼) æˆ– str (æ—§æ ¼å¼)
    if isinstance(session.last_result_file, dict):
        filename = session.last_result_file.get('filename', f"emission_result_{file_id}.xlsx")
        file_path_raw = session.last_result_file.get('path')
        if file_path_raw:
            file_path = Path(file_path_raw)
        else:
            from config import get_config
            config = get_config()
            file_path = config.outputs_dir / filename
    else:
        file_path = Path(session.last_result_file)
        filename = f"emission_result_{file_id}.xlsx"

    if not file_path.exists():
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    return FileResponse(
        path=file_path,
        filename=filename,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )


@router.get("/file/download/message/{session_id}/{message_id}")
async def download_file_by_message(session_id: str, message_id: str, request: Request, user_id: Optional[str] = Query(None)):
    """æŒ‰æ¶ˆæ¯IDä¸‹è½½ç»“æœæ–‡ä»¶ï¼ˆæ¶ˆæ¯çº§æŒä¹…ä¸‹è½½ï¼‰"""
    uid = user_id or get_user_id(request)
    session = SessionRegistry.get(uid).get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    target = None
    for idx, msg in enumerate(session._history):
        if msg.get("role") != "assistant":
            continue
        mid = msg.get("message_id")
        if mid == message_id:
            target = msg
            break
        if not mid and message_id == f"legacy-{idx}":
            target = msg
            break

    if not target:
        raise HTTPException(status_code=404, detail="æ¶ˆæ¯ä¸å­˜åœ¨")

    download_meta = target.get("download_file")
    file_path = None
    filename = None

    if isinstance(download_meta, dict):
        filename = download_meta.get("filename")
        path_raw = download_meta.get("path")
        if path_raw:
            file_path = Path(path_raw)

    if not file_path:
        td = target.get("table_data")
        if isinstance(td, dict):
            td_download = td.get("download")
            if isinstance(td_download, dict):
                filename = filename or td_download.get("filename")
        if filename:
            from config import get_config
            config = get_config()
            file_path = config.outputs_dir / filename

    if not file_path or not file_path.exists():
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    if not filename:
        filename = file_path.name

    return FileResponse(
        path=file_path,
        filename=filename,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

@router.get("/download/{filename}")
async def download_result_file(filename: str):
    """ä¸‹è½½è®¡ç®—ç»“æœæ–‡ä»¶ï¼ˆä»outputsç›®å½•ï¼‰"""
    from config import get_config
    config = get_config()
    outputs_dir = config.outputs_dir

    # å®‰å…¨æ£€æŸ¥ï¼šåªå…è®¸ä¸‹è½½ outputs ç›®å½•ä¸‹çš„æ–‡ä»¶
    file_path = outputs_dir / filename

    # é˜²æ­¢è·¯å¾„éå†æ”»å‡»
    if not str(file_path.resolve()).startswith(str(outputs_dir.resolve())):
        raise HTTPException(status_code=403, detail="Access denied")

    if not file_path.exists():
        raise HTTPException(status_code=404, detail="File not found")

    return FileResponse(
        path=str(file_path),
        filename=filename,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

@router.get("/file/template/{template_type}")
async def download_template(template_type: str):
    """ä¸‹è½½æ¨¡æ¿æ–‡ä»¶"""
    templates = {
        "trajectory": {
            "columns": ["t", "speed_kph", "acceleration_mps2", "grade_pct"],
            "data": [
                [0, 0, 0, 0],
                [1, 5, 1.39, 0],
                [2, 12, 1.94, 0],
                [3, 20, 2.22, 0],
                [4, 28, 2.22, 0],
            ]
        },
        "links": {
            "columns": ["link_id", "link_length_km", "traffic_flow_vph", "avg_speed_kph", "ä¹˜ç”¨è½¦%", "å…¬äº¤è½¦%", "è´§è½¦%"],
            "data": [
                ["Link_1", 2.5, 5000, 60, 70, 20, 10],
                ["Link_2", 1.8, 3500, 45, 60, 30, 10],
                ["Link_3", 3.2, 6000, 80, 80, 10, 10],
            ]
        }
    }

    if template_type not in templates:
        raise HTTPException(status_code=404, detail="æ¨¡æ¿ä¸å­˜åœ¨")

    template = templates[template_type]
    df = pd.DataFrame(template["data"], columns=template["columns"])

    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    file_path = TEMP_DIR / f"template_{template_type}.xlsx"
    df.to_excel(file_path, index=False)

    return FileResponse(
        path=file_path,
        filename=f"{template_type}_template.xlsx",
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

@router.get("/sessions", response_model=SessionListResponse)
async def list_sessions(request: Request):
    """è·å–ä¼šè¯åˆ—è¡¨"""
    user_id = get_user_id(request)
    mgr = SessionRegistry.get(user_id)
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ”µ æ”¶åˆ°ä¼šè¯åˆ—è¡¨è¯·æ±‚ (user={user_id})")
    sessions = mgr.list_sessions()
    logger.info(f"ğŸ“‹ è¿”å› {len(sessions)} ä¸ªä¼šè¯")
    if sessions:
        logger.info(f"ğŸ†” ä¼šè¯IDåˆ—è¡¨: {[s.session_id for s in sessions[:5]]}")
    logger.info(f"{'='*60}\n")
    return SessionListResponse(
        sessions=[
            SessionInfo(
                session_id=s.session_id,
                title=s.title,
                created_at=s.created_at,
                updated_at=s.updated_at,
                message_count=s.message_count
            )
            for s in sessions
        ]
    )

@router.post("/sessions/new")
async def create_session(request: Request):
    """åˆ›å»ºæ–°ä¼šè¯"""
    user_id = get_user_id(request)
    session_id = SessionRegistry.get(user_id).create_session()
    return {"session_id": session_id}

@router.delete("/sessions/{session_id}")
async def delete_session(session_id: str, request: Request):
    """åˆ é™¤ä¼šè¯"""
    user_id = get_user_id(request)
    SessionRegistry.get(user_id).delete_session(session_id)
    return {"status": "ok"}


@router.patch("/sessions/{session_id}/title")
async def update_session_title(session_id: str, payload: UpdateSessionTitleRequest, request: Request):
    """æ‰‹åŠ¨æ›´æ–°ä¼šè¯æ ‡é¢˜"""
    user_id = get_user_id(request)
    ok = SessionRegistry.get(user_id).set_session_title(session_id, payload.title)
    if not ok:
        raise HTTPException(status_code=400, detail="æ ‡é¢˜ä¸èƒ½ä¸ºç©ºæˆ–ä¼šè¯ä¸å­˜åœ¨")
    return {"status": "ok", "session_id": session_id, "title": payload.title.strip()[:80]}

@router.get("/sessions/{session_id}/history", response_model=HistoryResponse)
async def get_session_history(session_id: str, request: Request):
    """è·å–ä¼šè¯å†å²æ¶ˆæ¯"""
    user_id = get_user_id(request)
    mgr = SessionRegistry.get(user_id)
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ”µ æ”¶åˆ°å†å²è®°å½•è¯·æ±‚ (user={user_id})")
    logger.info(f"ğŸ†” ä¼šè¯ID: {session_id}")

    session = mgr.get_session(session_id)
    if not session:
        logger.error(f"âŒ ä¼šè¯ä¸å­˜åœ¨: {session_id}")
        logger.info(f"ğŸ“‹ å½“å‰ä¼šè¯åˆ—è¡¨: {list(mgr.sessions.keys())}")
        logger.info(f"{'='*60}\n")
        raise HTTPException(status_code=404, detail="Session not found")

    logger.info(f"âœ… ä¼šè¯æ‰¾åˆ°ï¼Œè·å–å†å²æ¶ˆæ¯...")
    messages = session._history

    # å›å¡«ä¸‹è½½å…ƒæ•°æ®ï¼ˆå…¼å®¹æ—§å†å²è®°å½•ï¼‰
    normalized_messages = []
    for idx, msg in enumerate(messages):
        msg_copy = dict(msg)
        if msg_copy.get("role") == "assistant":
            if not msg_copy.get("message_id"):
                msg_copy["message_id"] = f"legacy-{idx}"
            if not msg_copy.get("download_file"):
                td = msg_copy.get("table_data")
                if isinstance(td, dict):
                    td_download = td.get("download")
                    if isinstance(td_download, dict) and td_download.get("filename"):
                        filename = td_download.get("filename")
                        download_meta = {
                            "filename": filename,
                            "url": f"/api/file/download/message/{session_id}/{msg_copy['message_id']}",
                            "file_id": session_id
                        }
                        from config import get_config
                        config = get_config()
                        download_meta["path"] = str(config.outputs_dir / filename)
                        msg_copy["download_file"] = download_meta
            if not msg_copy.get("file_id") and msg_copy.get("download_file"):
                msg_copy["file_id"] = session_id
        normalized_messages.append(msg_copy)
    logger.info(f"ğŸ“ å†å²æ¶ˆæ¯æ•°é‡: {len(messages)}")

    # æ·»åŠ è°ƒè¯•æ—¥å¿—
    import sys
    for i, msg in enumerate(normalized_messages):
        if msg.get('role') == 'assistant':
            has_chart = msg.get('chart_data') is not None
            has_table = msg.get('table_data') is not None
            sys.stdout.write(f"[DEBUG] å†å²æ¶ˆæ¯{i}: role=assistant, chart_data={has_chart}, table_data={has_table}, data_type={msg.get('data_type')}\n")
            sys.stdout.flush()

    logger.info(f"{'='*60}\n")

    return HistoryResponse(
        session_id=session_id,
        messages=normalized_messages,
        success=True
    )

@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@router.get("/test")
async def test_endpoint():
    """æµ‹è¯•ç«¯ç‚¹ - éªŒè¯æ—¥å¿—æ˜¯å¦å·¥ä½œ"""
    import sys
    sys.stdout.write("\n" + "="*60 + "\n")
    sys.stdout.write("ğŸ§ª æµ‹è¯•ç«¯ç‚¹è¢«è°ƒç”¨\n")
    sys.stdout.write("="*60 + "\n")
    sys.stdout.flush()
    print("ğŸ§ª ä½¿ç”¨printè¾“å‡º", flush=True)
    logger.info("ğŸ§ª ä½¿ç”¨loggerè¾“å‡º")
    return {
        "status": "ok",
        "message": "æµ‹è¯•æˆåŠŸ - å¦‚æœä½ åœ¨ç»ˆç«¯çœ‹åˆ°è¿™æ¡æ¶ˆæ¯çš„æ—¥å¿—ï¼Œè¯´æ˜æ—¥å¿—ç³»ç»Ÿæ­£å¸¸å·¥ä½œ",
        "timestamp": datetime.now().isoformat()
    }
