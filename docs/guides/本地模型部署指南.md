# æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹éƒ¨ç½²ä¸é›†æˆæŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•å°†æœ¬åœ°å¾®è°ƒçš„Qwen3-4Bæ¨¡å‹é€šè¿‡VLLMæœåŠ¡é›†æˆåˆ°emission_agentç³»ç»Ÿä¸­ï¼Œå®ç°è½¦å‹å’Œæ±¡æŸ“ç‰©çš„æœ¬åœ°åŒ–æ ‡å‡†åŒ–åŠŸèƒ½ã€‚

### ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Windows (emission_agent)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  FastAPI Server (port 8000)                            â”‚ â”‚
â”‚  â”‚  â”œâ”€ Agent Core (qwen3-max)                             â”‚ â”‚
â”‚  â”‚  â”œâ”€ Vehicle Standardizer â”€â”€â”                           â”‚ â”‚
â”‚  â”‚  â””â”€ Pollutant Standardizer â”€â”¼â”€> LocalStandardizerClientâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                â”‚                              â”‚
â”‚                                â”‚ HTTP (no proxy)              â”‚
â”‚                                â†“                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   WSL2 Network Bridge   â”‚
                    â”‚   172.20.251.164:8001   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WSL2 (Ubuntu)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  VLLM Service (port 8001)  â”‚                            â”‚ â”‚
â”‚  â”‚  â”œâ”€ Base Model: Qwen3-4B-Instruct-2507                 â”‚ â”‚
â”‚  â”‚  â”œâ”€ LoRA Adapter: unified (vehicle + pollutant)        â”‚ â”‚
â”‚  â”‚  â””â”€ LoRA Adapter: column (column mapping)              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                               â”‚
â”‚  Model Storage:                                               â”‚
â”‚  ~/LOCAL_STANDARDIZER_MODEL/models/                           â”‚
â”‚  â”œâ”€ unified_lora_llamafactory/                                â”‚
â”‚  â””â”€ column_lora_llamafactory/                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æŠ€æœ¯æ ˆ

- **åŸºç¡€æ¨¡å‹**: Qwen3-4B-Instruct-2507 (4Bå‚æ•°)
- **å¾®è°ƒæ–¹æ³•**: LoRA (Low-Rank Adaptation)
- **æ¨ç†å¼•æ“**: VLLM 0.15.0 (é«˜æ€§èƒ½æ¨ç†æœåŠ¡å™¨)
- **é€šä¿¡åè®®**: HTTP REST API (OpenAIå…¼å®¹)
- **éƒ¨ç½²ç¯å¢ƒ**: WSL2 (Ubuntu) + Windows

---

## ğŸ¯ é›†æˆæ­¥éª¤

### æ­¥éª¤1: æ¨¡å‹è®­ç»ƒå‡†å¤‡

#### 1.1 è®­ç»ƒç¯å¢ƒè®¾ç½®

åœ¨WSL2ä¸­åˆ›å»ºè®­ç»ƒç¯å¢ƒï¼š

```bash
# è¿›å…¥WSL2
wsl

# åˆ›å»ºcondaç¯å¢ƒ
conda create -n local_standardizer python=3.10 -y
conda activate local_standardizer

# å®‰è£…ä¾èµ–
pip install torch transformers peft datasets accelerate vllm
```

#### 1.2 æ¨¡å‹è®­ç»ƒ

```bash
cd ~/LOCAL_STANDARDIZER_MODEL

# è®­ç»ƒunifiedæ¨¡å‹ï¼ˆè½¦å‹+æ±¡æŸ“ç‰©æ ‡å‡†åŒ–ï¼‰
python scripts/04_train_lora.py \
    --config configs/unified_lora_config.yaml \
    --model_type unified

# è®­ç»ƒcolumnæ¨¡å‹ï¼ˆåˆ—åæ˜ å°„ï¼‰
python scripts/04_train_lora.py \
    --config configs/column_lora_config.yaml \
    --model_type column
```

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¿å­˜åœ¨ï¼š
- `~/LOCAL_STANDARDIZER_MODEL/models/unified_lora_llamafactory/`
- `~/LOCAL_STANDARDIZER_MODEL/models/column_lora_llamafactory/`

---

### æ­¥éª¤2: VLLMæœåŠ¡éƒ¨ç½²

#### 2.1 å®‰è£…VLLM

```bash
# åœ¨WSL2çš„local_standardizerç¯å¢ƒä¸­
conda activate local_standardizer
pip install vllm
```

#### 2.2 å¯åŠ¨VLLMæœåŠ¡

```bash
cd ~/LOCAL_STANDARDIZER_MODEL

# å¯åŠ¨VLLMæœåŠ¡ï¼ˆå¸¦LoRAé€‚é…å™¨ï¼‰
vllm serve /home/kirito/Agent/DataFlow/finetunning/models/Qwen3-4B-Instruct-2507 \
    --enable-lora \
    --lora-modules unified=/home/kirito/LOCAL_STANDARDIZER_MODEL/models/unified_lora_llamafactory \
                   column=/home/kirito/LOCAL_STANDARDIZER_MODEL/models/column_lora_llamafactory \
    --port 8001 \
    --gpu-memory-utilization 0.8 \
    --max-model-len 2048 \
    --max-lora-rank 32
```

**å¯åŠ¨å‚æ•°è¯´æ˜**ï¼š
- `--enable-lora`: å¯ç”¨LoRAé€‚é…å™¨æ”¯æŒ
- `--lora-modules`: æŒ‡å®šLoRAé€‚é…å™¨åç§°å’Œè·¯å¾„
- `--port 8001`: æœåŠ¡ç«¯å£
- `--gpu-memory-utilization 0.8`: GPUæ˜¾å­˜åˆ©ç”¨ç‡ï¼ˆ80%ï¼‰
- `--max-model-len 2048`: æœ€å¤§åºåˆ—é•¿åº¦
- `--max-lora-rank 32`: æœ€å¤§LoRAç§©ï¼ˆéœ€è¦â‰¥è®­ç»ƒæ—¶çš„rankï¼‰

#### 2.3 éªŒè¯VLLMæœåŠ¡

å¯åŠ¨æˆåŠŸåï¼Œä½ ä¼šçœ‹åˆ°ï¼š

```
INFO: Started server process [xxxxx]
INFO: Application startup complete.
INFO: Loaded new LoRA adapter: name 'unified', path '...'
INFO: Loaded new LoRA adapter: name 'column', path '...'
```

æµ‹è¯•å¥åº·æ£€æŸ¥ï¼š

```bash
# åœ¨WSL2ä¸­æµ‹è¯•
curl http://localhost:8001/health
```

#### 2.4 è·å–WSL2 IPåœ°å€

```bash
# åœ¨WSL2ä¸­è¿è¡Œ
hostname -I | awk '{print $1}'
# è¾“å‡ºç¤ºä¾‹: 172.20.251.164
```

**é‡è¦**: è®°å½•è¿™ä¸ªIPåœ°å€ï¼Œåç»­é…ç½®éœ€è¦ä½¿ç”¨ã€‚

---

### æ­¥éª¤3: Windowsç«¯é…ç½®

#### 3.1 åˆ›å»ºæœ¬åœ°æ¨¡å‹å®¢æˆ·ç«¯

æ–‡ä»¶å·²å­˜åœ¨ï¼š`shared/standardizer/local_client.py`

å…³é”®åŠŸèƒ½ï¼š
- æ”¯æŒVLLMæ¨¡å¼å’Œç›´æ¥åŠ è½½æ¨¡å¼
- åŠ¨æ€åˆ‡æ¢LoRAé€‚é…å™¨
- ç¦ç”¨ä»£ç†è®¿é—®æœ¬åœ°æœåŠ¡

#### 3.2 æ›´æ–°é…ç½®æ–‡ä»¶

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œæ·»åŠ æœ¬åœ°æ¨¡å‹é…ç½®ï¼š

```bash
# ============ æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹é…ç½® ============
# æ˜¯å¦ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆtrue/falseï¼‰
USE_LOCAL_STANDARDIZER=true

# æ¨¡å¼ï¼šdirectï¼ˆç›´æ¥åŠ è½½ï¼‰æˆ– vllmï¼ˆVLLMæœåŠ¡ï¼‰
LOCAL_STANDARDIZER_MODE=vllm

# åŸºç¡€æ¨¡å‹è·¯å¾„ï¼ˆWSL2ä¸­çš„å®é™…è·¯å¾„ï¼‰
LOCAL_STANDARDIZER_BASE_MODEL=/home/kirito/Agent/DataFlow/finetunning/models/Qwen3-4B-Instruct-2507

# LoRAé€‚é…å™¨è·¯å¾„
LOCAL_STANDARDIZER_UNIFIED_LORA=./LOCAL_STANDARDIZER_MODEL/models/unified_lora/final
LOCAL_STANDARDIZER_COLUMN_LORA=./LOCAL_STANDARDIZER_MODEL/models/column_lora/checkpoint-200

# è®¾å¤‡ï¼šcuda æˆ– cpu
LOCAL_STANDARDIZER_DEVICE=cuda

# æœ€å¤§ç”Ÿæˆé•¿åº¦
LOCAL_STANDARDIZER_MAX_LENGTH=256

# VLLMæœåŠ¡åœ°å€ï¼ˆä½¿ç”¨WSL2çš„IPåœ°å€ï¼‰
LOCAL_STANDARDIZER_VLLM_URL=http://172.20.251.164:8001
```

**å…³é”®é…ç½®é¡¹**ï¼š
- `USE_LOCAL_STANDARDIZER=true`: å¯ç”¨æœ¬åœ°æ¨¡å‹
- `LOCAL_STANDARDIZER_MODE=vllm`: ä½¿ç”¨VLLMæ¨¡å¼
- `LOCAL_STANDARDIZER_VLLM_URL`: ä½¿ç”¨WSL2çš„å®é™…IPåœ°å€ï¼ˆä¸æ˜¯localhostï¼‰

#### 3.3 æ›´æ–°config.py

ç¼–è¾‘ `config.py`ï¼Œåœ¨ `Config` ç±»çš„ `__post_init__` æ–¹æ³•ä¸­æ·»åŠ ï¼š

```python
# ============ æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹é…ç½® ============
self.use_local_standardizer = os.getenv("USE_LOCAL_STANDARDIZER", "false").lower() == "true"

self.local_standardizer_config = {
    "enabled": self.use_local_standardizer,
    "mode": os.getenv("LOCAL_STANDARDIZER_MODE", "direct"),
    "base_model": os.getenv("LOCAL_STANDARDIZER_BASE_MODEL", "Qwen/Qwen2.5-3B-Instruct"),
    "unified_lora": os.getenv("LOCAL_STANDARDIZER_UNIFIED_LORA", "./LOCAL_STANDARDIZER_MODEL/models/unified_lora/final"),
    "column_lora": os.getenv("LOCAL_STANDARDIZER_COLUMN_LORA", "./LOCAL_STANDARDIZER_MODEL/models/column_lora/checkpoint-200"),
    "device": os.getenv("LOCAL_STANDARDIZER_DEVICE", "cuda"),
    "max_length": int(os.getenv("LOCAL_STANDARDIZER_MAX_LENGTH", "256")),
    "vllm_url": os.getenv("LOCAL_STANDARDIZER_VLLM_URL", "http://localhost:8001"),
}
```

---

### æ­¥éª¤4: é›†æˆåˆ°æ ‡å‡†åŒ–å™¨

#### 4.1 ä¿®æ”¹ vehicle.py

åœ¨ `VehicleStandardizer` ç±»ä¸­ï¼š

**ä¿®æ”¹ `__new__` æ–¹æ³•**ï¼š

```python
def __new__(cls):
    if cls._instance is None:
        cls._instance = super().__new__(cls)
        config = get_config()

        # é€‰æ‹©ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿˜æ˜¯API
        if config.use_local_standardizer:
            from .local_client import get_local_standardizer_client
            cls._instance._local_client = get_local_standardizer_client()
            cls._instance._use_local = True
            logger.info("ä½¿ç”¨æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹ï¼ˆè½¦å‹ï¼‰")
        else:
            cls._instance._llm = get_llm("standardizer") if config.enable_llm_standardization else None
            cls._instance._use_local = False
            logger.info("ä½¿ç”¨APIæ ‡å‡†åŒ–æ¨¡å‹ï¼ˆè½¦å‹ï¼‰")

        cls._instance._collector = get_collector()
        cls._instance._enable_llm = config.enable_llm_standardization or config.use_local_standardizer
        cls._instance._vehicle_list = "\n".join(
            f"- {std} ({cn}): {', '.join(aliases[:3])}"
            for std, (cn, aliases) in VEHICLE_TYPE_MAPPING.items()
        )
    return cls._instance
```

**ä¿®æ”¹ `_llm_standardize` æ–¹æ³•**ï¼š

```python
def _llm_standardize(self, user_input: str) -> Optional[StandardizationResult]:
    # ä½¿ç”¨æœ¬åœ°æ¨¡å‹
    if hasattr(self, '_use_local') and self._use_local:
        try:
            standard = self._local_client.standardize_vehicle(user_input)
            # éªŒè¯è¿”å›çš„æ ‡å‡†å€¼
            if standard in STANDARD_VEHICLE_TYPES:
                return StandardizationResult(user_input, standard, 0.95, "local_llm")
            else:
                logger.warning(f"æœ¬åœ°æ¨¡å‹è¿”å›äº†æ— æ•ˆçš„è½¦å‹: {standard}")
                return None
        except Exception as e:
            logger.error(f"æœ¬åœ°æ¨¡å‹æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return None

    # ä½¿ç”¨APIæ¨¡å‹ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    # ...
```

**ä¿®æ”¹ `_log` æ–¹æ³•**ï¼š

```python
def _log(self, user_input: str, result: StandardizationResult, context: Dict = None):
    model_name = None
    if hasattr(self, '_use_local') and self._use_local:
        model_name = "local_qwen3-4b"
    elif self._llm:
        model_name = self._llm.assignment.model

    self._collector.log(
        task="vehicle_type",
        input_value=user_input,
        output={"standard": result.standard, "confidence": result.confidence},
        method=result.method,
        model=model_name,
        context=context
    )
```

#### 4.2 ä¿®æ”¹ pollutant.py

å¯¹ `PollutantStandardizer` ç±»è¿›è¡Œç›¸åŒçš„ä¿®æ”¹ï¼ˆå‚è€ƒvehicle.pyï¼‰ã€‚

---

### æ­¥éª¤5: å¯åŠ¨å’Œæµ‹è¯•

#### 5.1 å¯åŠ¨æœåŠ¡

**ç»ˆç«¯1 (WSL2)**: å¯åŠ¨VLLMæœåŠ¡

```bash
cd ~/LOCAL_STANDARDIZER_MODEL
conda activate local_standardizer
./start_vllm.sh  # æˆ–ä½¿ç”¨ä¸Šé¢çš„vllm serveå‘½ä»¤
```

**ç»ˆç«¯2 (Windows PowerShell)**: å¯åŠ¨emission_agent

```powershell
cd D:\Agent_MCP\emission_agent
conda activate emission_agent
.\scripts\restart_server.ps1
```

#### 5.2 éªŒè¯é›†æˆ

åœ¨emission_agentçš„å¯åŠ¨æ—¥å¿—ä¸­ï¼ŒæŸ¥æ‰¾ä»¥ä¸‹ä¿¡æ¯ï¼š

```
âœ… æˆåŠŸæ ‡å¿—ï¼š
åˆå§‹åŒ–æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹ï¼ˆæ¨¡å¼: vllmï¼‰...
VLLMæœåŠ¡åœ°å€: http://172.20.251.164:8001
VLLMæœåŠ¡è¿æ¥æˆåŠŸ  â† å…³é”®ï¼
ä½¿ç”¨æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹ï¼ˆè½¦å‹ï¼‰
ä½¿ç”¨æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹ï¼ˆæ±¡æŸ“ç‰©ï¼‰
```

#### 5.3 åŠŸèƒ½æµ‹è¯•

è®¿é—® `http://localhost:8000`ï¼Œæµ‹è¯•ä»¥ä¸‹åœºæ™¯ï¼š

**æµ‹è¯•1: è§„åˆ™åŒ¹é…**
```
ç”¨æˆ·: è¯·å¸®æˆ‘è®¡ç®—å°æ±½è½¦çš„æ’æ”¾
é¢„æœŸ: é€šè¿‡è§„åˆ™åŒ¹é…ï¼Œmethod="rule", model="local_qwen3-4b"
```

**æµ‹è¯•2: LLMæ¨ç†**
```
ç”¨æˆ·: è¯·å¸®æˆ‘è®¡ç®—å®¶ç”¨å°è½¿è½¦çš„æ’æ”¾
é¢„æœŸ: è°ƒç”¨æœ¬åœ°LLMï¼Œmethod="local_llm", model="local_qwen3-4b"
```

**æµ‹è¯•3: å®è§‚æ’æ”¾è®¡ç®—**
```
ç”¨æˆ·: è¯·å¸®æˆ‘è®¡ç®—å°æ±½è½¦å’Œå…¬äº¤è½¦çš„å®è§‚æ’æ”¾
é¢„æœŸ: æˆåŠŸè°ƒç”¨å®è§‚æ’æ”¾æŠ€èƒ½ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡å‹æ ‡å‡†åŒ–è½¦å‹
```

#### 5.4 æŸ¥çœ‹æ•°æ®æ”¶é›†æ—¥å¿—

```bash
# æŸ¥çœ‹æœ€è¿‘çš„è½¦å‹æ ‡å‡†åŒ–è®°å½•
tail -10 data/collection/vehicle_type.jsonl
```

ç¡®è®¤æ—¥å¿—ä¸­æ˜¾ç¤º `"model": "local_qwen3-4b"`ã€‚

---

## ğŸ”§ å…³é”®æŠ€æœ¯ç»†èŠ‚

### ä»£ç†é…ç½®å¤„ç†

**é—®é¢˜**: emission_agenté…ç½®äº†HTTPä»£ç†ï¼ˆ`HTTP_PROXY=http://127.0.0.1:7890`ï¼‰ï¼Œå¯¼è‡´æ— æ³•è¿æ¥æœ¬åœ°VLLMæœåŠ¡ã€‚

**è§£å†³æ–¹æ¡ˆ**: åœ¨ `local_client.py` ä¸­ï¼Œæ‰€æœ‰requestsè°ƒç”¨éƒ½æ·»åŠ  `proxies={"http": None, "https": None}` å‚æ•°ï¼š

```python
def _init_vllm_mode(self):
    response = requests.get(
        f"{self.vllm_url}/health",
        timeout=2,
        proxies={"http": None, "https": None}  # ç¦ç”¨ä»£ç†
    )
```

### WSL2ç½‘ç»œé…ç½®

**é—®é¢˜**: Windowsæ— æ³•é€šè¿‡ `localhost:8001` è®¿é—®WSL2ä¸­çš„æœåŠ¡ã€‚

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨WSL2çš„å®é™…IPåœ°å€ï¼ˆ`172.20.251.164`ï¼‰è€Œä¸æ˜¯localhostã€‚

**æ³¨æ„**: WSL2çš„IPåœ°å€åœ¨æ¯æ¬¡é‡å¯åå¯èƒ½ä¼šå˜åŒ–ã€‚å¦‚æœé‡å¯ç”µè„‘åæ— æ³•è¿æ¥ï¼Œéœ€è¦ï¼š
1. åœ¨WSL2ä¸­è¿è¡Œ `hostname -I` è·å–æ–°IP
2. æ›´æ–° `.env` ä¸­çš„ `LOCAL_STANDARDIZER_VLLM_URL`

### LoRAé€‚é…å™¨åˆ‡æ¢

VLLMæ”¯æŒåŠ¨æ€åˆ‡æ¢LoRAé€‚é…å™¨ï¼Œé€šè¿‡åœ¨è¯·æ±‚ä¸­æŒ‡å®š `model` å‚æ•°ï¼š

```python
response = requests.post(
    f"{self.vllm_url}/v1/completions",
    json={
        "model": "unified",  # æˆ– "column"
        "prompt": prompt,
        "max_tokens": 256,
        "temperature": 0.1
    }
)
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | APIæ¨¡å¼ (qwen-flash) | æœ¬åœ°VLLMæ¨¡å¼ (qwen3-4b) |
|------|---------------------|------------------------|
| é¦–æ¬¡å»¶è¿Ÿ | ~500ms | ~100ms |
| åç»­å»¶è¿Ÿ | ~500ms | ~50ms |
| æ˜¾å­˜å ç”¨ | 0 | ~4GB |
| å¹¶å‘æ”¯æŒ | é«˜ | é«˜ |
| æˆæœ¬ | æŒ‰è°ƒç”¨è®¡è´¹ | å…è´¹ |
| æ•°æ®éšç§ | äº‘ç«¯ | å®Œå…¨æœ¬åœ° |
| ç½‘ç»œä¾èµ– | éœ€è¦ | ä¸éœ€è¦ |

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜1: VLLMæœåŠ¡æ— æ³•å¯åŠ¨

**ç—‡çŠ¶**:
```
CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# é™ä½GPUæ˜¾å­˜åˆ©ç”¨ç‡
vllm serve ... --gpu-memory-utilization 0.6
```

### é—®é¢˜2: Windowsæ— æ³•è¿æ¥VLLMæœåŠ¡

**ç—‡çŠ¶**:
```
æ— æ³•è¿æ¥åˆ°VLLMæœåŠ¡: Connection timeout
```

**æ’æŸ¥æ­¥éª¤**:

1. ç¡®è®¤VLLMæœåŠ¡æ­£åœ¨è¿è¡Œï¼š
   ```bash
   # åœ¨WSL2ä¸­
   curl http://localhost:8001/health
   ```

2. è·å–WSL2 IPåœ°å€ï¼š
   ```bash
   hostname -I
   ```

3. æ›´æ–° `.env` ä¸­çš„ `LOCAL_STANDARDIZER_VLLM_URL`

4. æµ‹è¯•è¿æ¥ï¼š
   ```powershell
   # åœ¨Windows PowerShellä¸­
   curl http://172.20.251.164:8001/health
   ```

### é—®é¢˜3: ä»£ç†å¹²æ‰°

**ç—‡çŠ¶**:
```
HTTPConnectionPool(host='127.0.0.1', port=7890): Read timed out
```

**è§£å†³æ–¹æ¡ˆ**: ç¡®è®¤ `local_client.py` ä¸­æ‰€æœ‰requestsè°ƒç”¨éƒ½æ·»åŠ äº† `proxies={"http": None, "https": None}`ã€‚

### é—®é¢˜4: æ¨¡å‹è¿”å›æ— æ•ˆç»“æœ

**ç—‡çŠ¶**: æ—¥å¿—æ˜¾ç¤º "æœ¬åœ°æ¨¡å‹è¿”å›äº†æ— æ•ˆçš„è½¦å‹"

**æ’æŸ¥æ­¥éª¤**:

1. æ£€æŸ¥LoRAé€‚é…å™¨æ˜¯å¦æ­£ç¡®åŠ è½½ï¼š
   ```bash
   # åœ¨VLLMå¯åŠ¨æ—¥å¿—ä¸­æŸ¥æ‰¾
   INFO: Loaded new LoRA adapter: name 'unified'
   ```

2. æµ‹è¯•VLLMæœåŠ¡ï¼š
   ```bash
   curl -X POST http://172.20.251.164:8001/v1/completions \
     -H "Content-Type: application/json" \
     -d '{
       "model": "unified",
       "prompt": "[vehicle] å°æ±½è½¦",
       "max_tokens": 50,
       "temperature": 0.1
     }'
   ```

3. æ£€æŸ¥è®­ç»ƒæ•°æ®è´¨é‡å’Œæ¨¡å‹checkpoint

---

## ğŸ”„ åˆ‡æ¢å›APIæ¨¡å¼

å¦‚æœéœ€è¦åˆ‡æ¢å›APIæ¨¡å¼ï¼š

1. ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š
   ```bash
   USE_LOCAL_STANDARDIZER=false
   ```

2. é‡å¯æœåŠ¡å™¨ï¼š
   ```powershell
   .\scripts\restart_server.ps1
   ```

3. éªŒè¯æ—¥å¿—ï¼š
   ```
   ä½¿ç”¨APIæ ‡å‡†åŒ–æ¨¡å‹ï¼ˆè½¦å‹ï¼‰
   ä½¿ç”¨APIæ ‡å‡†åŒ–æ¨¡å‹ï¼ˆæ±¡æŸ“ç‰©ï¼‰
   ```

---

## ğŸ“ ç»´æŠ¤å»ºè®®

### æ—¥å¸¸è¿ç»´

1. **ç›‘æ§VLLMæœåŠ¡çŠ¶æ€**
   ```bash
   # åœ¨WSL2ä¸­
   curl http://localhost:8001/health
   ```

2. **æŸ¥çœ‹VLLMæ—¥å¿—**
   - VLLMæœåŠ¡çš„æ—¥å¿—ä¼šå®æ—¶æ˜¾ç¤ºåœ¨å¯åŠ¨ç»ˆç«¯
   - å…³æ³¨GPUæ˜¾å­˜ä½¿ç”¨ç‡å’Œè¯·æ±‚ååé‡

3. **å®šæœŸæ£€æŸ¥æ•°æ®æ”¶é›†æ—¥å¿—**
   ```bash
   tail -f data/collection/vehicle_type.jsonl
   ```

### æ¨¡å‹æ›´æ–°

å½“éœ€è¦æ›´æ–°æ¨¡å‹æ—¶ï¼š

1. åœ¨WSL2ä¸­é‡æ–°è®­ç»ƒæ¨¡å‹
2. åœæ­¢VLLMæœåŠ¡ï¼ˆCtrl+Cï¼‰
3. æ›´æ–° `.env` ä¸­çš„LoRAè·¯å¾„ï¼ˆå¦‚æœè·¯å¾„å˜åŒ–ï¼‰
4. é‡æ–°å¯åŠ¨VLLMæœåŠ¡
5. é‡å¯emission_agentæœåŠ¡å™¨

### å¤‡ä»½å»ºè®®

å®šæœŸå¤‡ä»½ä»¥ä¸‹å†…å®¹ï¼š
- è®­ç»ƒå¥½çš„LoRAé€‚é…å™¨ï¼š`~/LOCAL_STANDARDIZER_MODEL/models/`
- é…ç½®æ–‡ä»¶ï¼š`.env`, `config.py`
- æ•°æ®æ”¶é›†æ—¥å¿—ï¼š`data/collection/`

---

## ğŸ¯ æ€»ç»“

æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹é›†æˆå®Œæˆåï¼Œç³»ç»Ÿå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š

âœ… **åŠŸèƒ½å®Œæ•´æ€§**
- è½¦å‹æ ‡å‡†åŒ–ï¼ˆ13ç§MOVESæ ‡å‡†è½¦å‹ï¼‰
- æ±¡æŸ“ç‰©æ ‡å‡†åŒ–ï¼ˆ7ç§æ ‡å‡†æ±¡æŸ“ç‰©ï¼‰
- åˆ—åæ˜ å°„ï¼ˆExcelè¡¨æ ¼æ™ºèƒ½è¯†åˆ«ï¼‰

âœ… **æ€§èƒ½ä¼˜åŠ¿**
- æ¨ç†å»¶è¿Ÿé™ä½80%ï¼ˆ500ms â†’ 50msï¼‰
- æ— APIè°ƒç”¨æˆæœ¬
- æ”¯æŒé«˜å¹¶å‘è¯·æ±‚

âœ… **æ•°æ®å®‰å…¨**
- å®Œå…¨æœ¬åœ°åŒ–å¤„ç†
- æ— æ•°æ®å¤–ä¼ é£é™©
- ç¬¦åˆæ•°æ®éšç§è¦æ±‚

âœ… **å¯ç»´æŠ¤æ€§**
- é…ç½®çµæ´»ï¼Œæ”¯æŒAPI/æœ¬åœ°æ¨¡å¼åˆ‡æ¢
- æ—¥å¿—å®Œæ•´ï¼Œä¾¿äºé—®é¢˜æ’æŸ¥
- æ¨¡å‹å¯ç‹¬ç«‹æ›´æ–°

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [VLLMå®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/)
- [LoRAè®ºæ–‡](https://arxiv.org/abs/2106.09685)
- [Qwenæ¨¡å‹æ–‡æ¡£](https://github.com/QwenLM/Qwen)
- [WSL2ç½‘ç»œé…ç½®](https://learn.microsoft.com/en-us/windows/wsl/networking)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-02-01
**ç»´æŠ¤è€…**: Emission Agent Team
