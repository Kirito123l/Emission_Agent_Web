# æœ¬åœ°æ¨¡å‹é›†æˆåˆ†ææŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦

âœ… **æ•°æ®å‡†å¤‡å®Œæˆ**: è®­ç»ƒæ•°æ®å·²å°±ç»ªï¼ˆç»Ÿä¸€æ¨¡å‹5,121æ¡ï¼Œåˆ—åæ˜ å°„1,000æ¡ï¼‰

âš ï¸ **é›†æˆéœ€è¦é€‚é…å±‚**: æœ¬åœ°æ¨¡å‹çš„è¾“å…¥è¾“å‡ºæ ¼å¼ä¸ç°æœ‰å·¥ä½œæµå­˜åœ¨å·®å¼‚ï¼Œéœ€è¦åˆ›å»ºé€‚é…å±‚

## 1. å½“å‰å·¥ä½œæµåˆ†æ

### 1.1 è½¦å‹/æ±¡æŸ“ç‰©æ ‡å‡†åŒ–

**ç°æœ‰æ¥å£**:
```python
# shared/standardizer/vehicle.py
class VehicleStandardizer:
    def standardize(self, user_input: str, context: Dict = None) -> StandardizationResult:
        # è¿”å› StandardizationResult å¯¹è±¡
        pass

@dataclass
class StandardizationResult:
    input: str
    standard: Optional[str]  # æ ‡å‡†åŒ–åçš„å€¼
    confidence: float        # ç½®ä¿¡åº¦
    method: str             # æ–¹æ³• (rule/llm/rule_fallback)
    error: Optional[str]    # é”™è¯¯ä¿¡æ¯
```

**è°ƒç”¨æ–¹å¼**:
```python
# skills/micro_emission/skill.py
v_result = self._vehicle_std.standardize(vehicle_type, context)
if not v_result.standard:
    return SkillResult(success=False, error=f"æ— æ³•è¯†åˆ«è½¦å‹: {vehicle_type}")

# ä½¿ç”¨æ ‡å‡†åŒ–ç»“æœ
result = self._calculator.calculate(
    vehicle_type=v_result.standard,  # ä½¿ç”¨ .standard å±æ€§
    ...
)
```

**æœ¬åœ°æ¨¡å‹æ ¼å¼**:
- è¾“å…¥: `[vehicle] å¤§è´§è½¦`
- è¾“å‡º: `Combination Long-haul Truck` (çº¯å­—ç¬¦ä¸²)
- æ ¼å¼: Qwen3 èŠå¤©æ ¼å¼

### 1.2 åˆ—åæ˜ å°„

**ç°æœ‰æ¥å£**:
```python
# skills/common/column_mapper.py
def map_columns_with_llm(
    file_info: Dict[str, Any],  # åŒ…å« columns, sample_data
    task_type: str,              # "micro_emission" æˆ– "macro_emission"
    llm_client: Any
) -> Optional[Dict[str, Any]]:
    # è¿”å›å¤æ‚çš„JSONç»“æ„
    pass
```

**æœŸæœ›è¾“å‡º**:
```json
{
    "mapping": {
        "ç”¨æˆ·åˆ—å1": "æ ‡å‡†å­—æ®µå1",
        "ç”¨æˆ·åˆ—å2": "æ ‡å‡†å­—æ®µå2"
    },
    "fleet_mix": {
        "ç”¨æˆ·è½¦å‹åˆ—å1": "æ ‡å‡†è½¦å‹å1"
    },
    "confidence": 0.95,
    "warnings": ["å¯èƒ½çš„é—®é¢˜1"],
    "unmapped_columns": ["æ— æ³•è¯†åˆ«çš„åˆ—1"]
}
```

**æœ¬åœ°æ¨¡å‹æ ¼å¼**:
- è¾“å…¥: `["è½¦é€Ÿkm/h", "åŠ é€Ÿåº¦", "æ—¶é—´"]`
- è¾“å‡º: `{"è½¦é€Ÿkm/h": "speed_kph", "åŠ é€Ÿåº¦": "acceleration_mps2", "æ—¶é—´": "time_sec"}` (ç®€å•æ˜ å°„)
- æ ¼å¼: Qwen3 èŠå¤©æ ¼å¼

## 2. é›†æˆé—®é¢˜æ¸…å•

### é—®é¢˜1: è¿”å›ç±»å‹ä¸åŒ¹é… âš ï¸

**é—®é¢˜æè¿°**:
- ç°æœ‰æ¥å£è¿”å› `StandardizationResult` å¯¹è±¡ï¼ˆåŒ…å« standard, confidence, method, errorï¼‰
- æœ¬åœ°æ¨¡å‹è¿”å›çº¯å­—ç¬¦ä¸²

**å½±å“èŒƒå›´**:
- `VehicleStandardizer.standardize()`
- `PollutantStandardizer.standardize()`

**è§£å†³æ–¹æ¡ˆ**: åˆ›å»ºé€‚é…å™¨åŒ…è£…æ¨¡å‹è¾“å‡º

### é—®é¢˜2: åˆ—åæ˜ å°„è¾“å‡ºæ ¼å¼ä¸å®Œæ•´ âš ï¸

**é—®é¢˜æè¿°**:
- ç°æœ‰æ¥å£æœŸæœ›è¿”å›åŒ…å« `mapping`, `fleet_mix`, `confidence`, `warnings`, `unmapped_columns` çš„å®Œæ•´JSON
- æœ¬åœ°æ¨¡å‹åªè¿”å›ç®€å•çš„ `{"åˆ—å": "æ ‡å‡†å­—æ®µ"}` æ˜ å°„

**å½±å“èŒƒå›´**:
- `map_columns_with_llm()`

**è§£å†³æ–¹æ¡ˆ**: é€‚é…å™¨éœ€è¦è¡¥å……ç¼ºå¤±å­—æ®µ

### é—®é¢˜3: è¾“å…¥æ ¼å¼å·®å¼‚ âš ï¸

**é—®é¢˜æè¿°**:
- è½¦å‹/æ±¡æŸ“ç‰©: éœ€è¦æ·»åŠ  `[vehicle]` æˆ– `[pollutant]` å‰ç¼€
- åˆ—åæ˜ å°„: ç°æœ‰ç³»ç»Ÿä¼ é€’å®Œæ•´æ–‡ä»¶ä¿¡æ¯ï¼ˆåŒ…æ‹¬æ ·æœ¬æ•°æ®ï¼‰ï¼Œæœ¬åœ°æ¨¡å‹åªéœ€è¦åˆ—ååˆ—è¡¨

**å½±å“èŒƒå›´**:
- æ‰€æœ‰æ ‡å‡†åŒ–è°ƒç”¨

**è§£å†³æ–¹æ¡ˆ**: é€‚é…å™¨å¤„ç†è¾“å…¥æ ¼å¼è½¬æ¢

### é—®é¢˜4: ç¼ºå°‘ç½®ä¿¡åº¦å’Œé”™è¯¯å¤„ç† âš ï¸

**é—®é¢˜æè¿°**:
- ç°æœ‰æ¥å£æä¾›ç½®ä¿¡åº¦è¯„åˆ†å’Œè¯¦ç»†é”™è¯¯ä¿¡æ¯
- æœ¬åœ°æ¨¡å‹åªè¿”å›ç»“æœï¼Œæ²¡æœ‰ç½®ä¿¡åº¦

**å½±å“èŒƒå›´**:
- æ—¥å¿—è®°å½•
- æ•°æ®æ”¶é›†
- é”™è¯¯å¤„ç†

**è§£å†³æ–¹æ¡ˆ**: é€‚é…å™¨æä¾›é»˜è®¤ç½®ä¿¡åº¦ï¼ˆå¦‚0.9ï¼‰ï¼Œå¹¶å¤„ç†è§£æé”™è¯¯

## 3. æ¨èçš„é›†æˆæ–¹æ¡ˆ

### æ–¹æ¡ˆA: åˆ›å»ºæœ¬åœ°æ ‡å‡†åŒ–å™¨é€‚é…ç±» âœ… æ¨è

**ä¼˜ç‚¹**:
- å®Œå…¨å…¼å®¹ç°æœ‰æ¥å£
- æ— éœ€ä¿®æ”¹ç°æœ‰ä»£ç 
- æ˜“äºåˆ‡æ¢ï¼ˆäº‘ç«¯ vs æœ¬åœ°ï¼‰

**å®ç°**:
```python
# shared/standardizer/local_client.py

from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
from .vehicle import StandardizationResult
import json

class LocalStandardizer:
    """æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹å®¢æˆ·ç«¯"""

    def __init__(self, config):
        self.base_model = config["base_model"]
        self.unified_lora_path = config["unified_lora"]
        self.column_lora_path = config["column_lora"]

        # åŠ è½½æ¨¡å‹å’Œtokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.base_model,
            trust_remote_code=True
        )

        # åŠ è½½ç»Ÿä¸€æ¨¡å‹ï¼ˆè½¦å‹+æ±¡æŸ“ç‰©ï¼‰
        self.unified_model = self._load_model(self.unified_lora_path)

        # åŠ è½½åˆ—åæ˜ å°„æ¨¡å‹
        self.column_model = self._load_model(self.column_lora_path)

    def _load_model(self, lora_path):
        """åŠ è½½LoRAæ¨¡å‹"""
        model = AutoModelForCausalLM.from_pretrained(
            self.base_model,
            trust_remote_code=True,
            torch_dtype=torch.float16,
            device_map="auto"
        )
        model = PeftModel.from_pretrained(model, lora_path)
        model.eval()
        return model

    def standardize_vehicle(self, user_input: str, context: Dict = None) -> StandardizationResult:
        """
        è½¦å‹æ ‡å‡†åŒ–ï¼ˆå…¼å®¹ç°æœ‰æ¥å£ï¼‰
        """
        try:
            # æ„å»ºè¾“å…¥
            messages = [
                {"role": "system", "content": UNIFIED_SYSTEM_PROMPT},
                {"role": "user", "content": f"[vehicle] {user_input}"}
            ]

            # ç”Ÿæˆ
            response = self._generate(self.unified_model, messages)

            # éªŒè¯è¾“å‡ºæ˜¯å¦ä¸ºæœ‰æ•ˆè½¦å‹
            if response in STANDARD_VEHICLE_TYPES:
                return StandardizationResult(
                    input=user_input,
                    standard=response,
                    confidence=0.9,  # æœ¬åœ°æ¨¡å‹é»˜è®¤ç½®ä¿¡åº¦
                    method="local_model"
                )
            else:
                return StandardizationResult(
                    input=user_input,
                    standard=None,
                    confidence=0.0,
                    method="local_model",
                    error=f"æ¨¡å‹è¾“å‡ºæ— æ•ˆ: {response}"
                )
        except Exception as e:
            return StandardizationResult(
                input=user_input,
                standard=None,
                confidence=0.0,
                method="local_model",
                error=str(e)
            )

    def standardize_pollutant(self, user_input: str, context: Dict = None) -> StandardizationResult:
        """
        æ±¡æŸ“ç‰©æ ‡å‡†åŒ–ï¼ˆå…¼å®¹ç°æœ‰æ¥å£ï¼‰
        """
        try:
            messages = [
                {"role": "system", "content": UNIFIED_SYSTEM_PROMPT},
                {"role": "user", "content": f"[pollutant] {user_input}"}
            ]

            response = self._generate(self.unified_model, messages)

            if response in STANDARD_POLLUTANTS:
                return StandardizationResult(
                    input=user_input,
                    standard=response,
                    confidence=0.9,
                    method="local_model"
                )
            else:
                return StandardizationResult(
                    input=user_input,
                    standard=None,
                    confidence=0.0,
                    method="local_model",
                    error=f"æ¨¡å‹è¾“å‡ºæ— æ•ˆ: {response}"
                )
        except Exception as e:
            return StandardizationResult(
                input=user_input,
                standard=None,
                confidence=0.0,
                method="local_model",
                error=str(e)
            )

    def map_columns(self, file_info: Dict, task_type: str) -> Optional[Dict]:
        """
        åˆ—åæ˜ å°„ï¼ˆå…¼å®¹ç°æœ‰æ¥å£ï¼‰
        """
        try:
            # æå–åˆ—å
            columns = file_info["columns"]

            # é€‰æ‹©system prompt
            if task_type == "micro_emission":
                system_prompt = COLUMN_MICRO_SYSTEM_PROMPT
            else:
                system_prompt = COLUMN_MACRO_SYSTEM_PROMPT

            # æ„å»ºè¾“å…¥
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": json.dumps(columns, ensure_ascii=False)}
            ]

            # ç”Ÿæˆ
            response = self._generate(self.column_model, messages, max_new_tokens=256)

            # è§£æJSON
            mapping = json.loads(response)

            # è¡¥å……ç¼ºå¤±å­—æ®µä»¥å…¼å®¹ç°æœ‰æ¥å£
            result = {
                "mapping": mapping,
                "fleet_mix": {},  # ä»mappingä¸­æå–è½¦å‹åˆ—
                "confidence": 0.9,
                "warnings": [],
                "unmapped_columns": []
            }

            # è¯†åˆ«è½¦å‹åˆ—ï¼ˆå€¼ä¸ºMOVESè½¦å‹åçš„åˆ—ï¼‰
            for col, std_field in mapping.items():
                if std_field in STANDARD_VEHICLE_TYPES:
                    result["fleet_mix"][col] = std_field
                    del result["mapping"][col]

            # è¯†åˆ«æœªæ˜ å°„çš„åˆ—
            result["unmapped_columns"] = [
                col for col in columns if col not in mapping
            ]

            return result

        except Exception as e:
            logger.error(f"[æœ¬åœ°æ¨¡å‹] åˆ—åæ˜ å°„å¤±è´¥: {e}")
            return None

    def _generate(self, model, messages, max_new_tokens=128):
        """ç”Ÿæˆå“åº”"""
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )

        inputs = self.tokenizer(text, return_tensors="pt").to(model.device)

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                temperature=0.1,
                do_sample=False,
                pad_token_id=self.tokenizer.pad_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
            )

        response = self.tokenizer.decode(
            outputs[0][inputs["input_ids"].shape[1]:],
            skip_special_tokens=True
        )
        return response.strip()
```

### æ–¹æ¡ˆB: ä¿®æ”¹ç°æœ‰ä»£ç  âŒ ä¸æ¨è

**ç¼ºç‚¹**:
- éœ€è¦ä¿®æ”¹å¤šä¸ªæ–‡ä»¶
- ç ´åç°æœ‰æ¥å£
- éš¾ä»¥å›é€€åˆ°äº‘ç«¯API

## 4. é…ç½®é›†æˆ

### 4.1 æ›´æ–° config.py

```python
# config.py

# æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹é…ç½®
LOCAL_STANDARDIZER_CONFIG = {
    "enabled": True,  # æ˜¯å¦å¯ç”¨æœ¬åœ°æ¨¡å‹
    "base_model": "Qwen/Qwen2.5-3B-Instruct",
    "unified_lora": "./LOCAL_STANDARDIZER_MODEL/models/unified_lora/final",
    "column_lora": "./LOCAL_STANDARDIZER_MODEL/models/column_lora/final",
    "device": "cuda",  # æˆ– "cpu"
}
```

### 4.2 ä¿®æ”¹æ ‡å‡†åŒ–å™¨åˆå§‹åŒ–

```python
# shared/standardizer/vehicle.py

def get_vehicle_standardizer():
    """è·å–è½¦å‹æ ‡å‡†åŒ–å™¨ï¼ˆæ”¯æŒæœ¬åœ°æ¨¡å‹ï¼‰"""
    config = get_config()

    if config.LOCAL_STANDARDIZER_CONFIG.get("enabled"):
        # ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        from .local_client import LocalStandardizer
        local_std = LocalStandardizer(config.LOCAL_STANDARDIZER_CONFIG)

        # è¿”å›å…¼å®¹çš„æ¥å£
        class LocalVehicleStandardizer:
            def standardize(self, user_input, context=None):
                return local_std.standardize_vehicle(user_input, context)

        return LocalVehicleStandardizer()
    else:
        # ä½¿ç”¨åŸæœ‰çš„äº‘ç«¯API
        return VehicleStandardizer()
```

### 4.3 ä¿®æ”¹åˆ—åæ˜ å°„è°ƒç”¨

```python
# skills/common/column_mapper.py

def map_columns_with_llm(file_info, task_type, llm_client):
    """æ™ºèƒ½åˆ—åæ˜ å°„ï¼ˆæ”¯æŒæœ¬åœ°æ¨¡å‹ï¼‰"""
    config = get_config()

    if config.LOCAL_STANDARDIZER_CONFIG.get("enabled"):
        # ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        from shared.standardizer.local_client import LocalStandardizer
        local_std = LocalStandardizer(config.LOCAL_STANDARDIZER_CONFIG)
        return local_std.map_columns(file_info, task_type)
    else:
        # ä½¿ç”¨åŸæœ‰çš„LLM
        # ... ç°æœ‰ä»£ç  ...
```

## 5. é›†æˆæ£€æŸ¥æ¸…å•

### 5.1 ä»£ç ä¿®æ”¹

- [ ] åˆ›å»º `shared/standardizer/local_client.py`
- [ ] æ›´æ–° `config.py` æ·»åŠ æœ¬åœ°æ¨¡å‹é…ç½®
- [ ] ä¿®æ”¹ `shared/standardizer/vehicle.py` çš„ `get_vehicle_standardizer()`
- [ ] ä¿®æ”¹ `shared/standardizer/pollutant.py` çš„ `get_pollutant_standardizer()`
- [ ] ä¿®æ”¹ `skills/common/column_mapper.py` çš„ `map_columns_with_llm()`

### 5.2 ä¾èµ–å®‰è£…

- [ ] å®‰è£… PyTorch (GPUç‰ˆæœ¬)
- [ ] å®‰è£… transformers
- [ ] å®‰è£… peft
- [ ] å®‰è£… accelerate

### 5.3 æ¨¡å‹æ–‡ä»¶

- [ ] è®­ç»ƒç»Ÿä¸€æ¨¡å‹ï¼ˆè½¦å‹+æ±¡æŸ“ç‰©ï¼‰
- [ ] è®­ç»ƒåˆ—åæ˜ å°„æ¨¡å‹
- [ ] éªŒè¯æ¨¡å‹å‡†ç¡®ç‡è¾¾æ ‡
- [ ] å°†æ¨¡å‹æ–‡ä»¶æ”¾ç½®åˆ°æŒ‡å®šè·¯å¾„

### 5.4 æµ‹è¯•

- [ ] å•å…ƒæµ‹è¯•ï¼šè½¦å‹æ ‡å‡†åŒ–
- [ ] å•å…ƒæµ‹è¯•ï¼šæ±¡æŸ“ç‰©æ ‡å‡†åŒ–
- [ ] å•å…ƒæµ‹è¯•ï¼šåˆ—åæ˜ å°„
- [ ] é›†æˆæµ‹è¯•ï¼šå¾®è§‚æ’æ”¾è®¡ç®—
- [ ] é›†æˆæµ‹è¯•ï¼šå®è§‚æ’æ”¾è®¡ç®—
- [ ] æ€§èƒ½æµ‹è¯•ï¼šæ¨ç†é€Ÿåº¦
- [ ] å¯¹æ¯”æµ‹è¯•ï¼šæœ¬åœ° vs äº‘ç«¯å‡†ç¡®ç‡

## 6. æ½œåœ¨é£é™©å’Œç¼“è§£æªæ–½

### é£é™©1: æ¨ç†é€Ÿåº¦æ…¢ âš ï¸

**é£é™©**: æœ¬åœ°æ¨¡å‹æ¨ç†å¯èƒ½æ¯”äº‘ç«¯APIæ…¢

**ç¼“è§£**:
- ä½¿ç”¨ GPU åŠ é€Ÿ
- æ‰¹é‡å¤„ç†å¤šä¸ªæ ‡å‡†åŒ–è¯·æ±‚
- æ·»åŠ ç¼“å­˜å±‚ï¼ˆç›¸åŒè¾“å…¥ç›´æ¥è¿”å›ç¼“å­˜ç»“æœï¼‰
- è€ƒè™‘æ¨¡å‹é‡åŒ–ï¼ˆINT8/INT4ï¼‰

### é£é™©2: å‡†ç¡®ç‡ä¸è¾¾æ ‡ âš ï¸

**é£é™©**: å¾®è°ƒåçš„æ¨¡å‹å‡†ç¡®ç‡å¯èƒ½ä½äºäº‘ç«¯API

**ç¼“è§£**:
- è®¾ç½®å‡†ç¡®ç‡é˜ˆå€¼ï¼Œä½äºé˜ˆå€¼æ—¶å›é€€åˆ°äº‘ç«¯API
- æŒç»­æ”¶é›†é”™è¯¯æ¡ˆä¾‹ï¼Œè¡¥å……è®­ç»ƒæ•°æ®
- å®ç°æ··åˆç­–ç•¥ï¼šæœ¬åœ°æ¨¡å‹ä¼˜å…ˆï¼Œå¤±è´¥æ—¶è°ƒç”¨äº‘ç«¯

### é£é™©3: æ˜¾å­˜å ç”¨ âš ï¸

**é£é™©**: åŠ è½½ä¸¤ä¸ªæ¨¡å‹å¯èƒ½å ç”¨å¤§é‡æ˜¾å­˜

**ç¼“è§£**:
- ä½¿ç”¨æ¨¡å‹é‡åŒ–
- æŒ‰éœ€åŠ è½½æ¨¡å‹ï¼ˆç”¨æ—¶åŠ è½½ï¼Œç”¨å®Œå¸è½½ï¼‰
- ä½¿ç”¨ CPU æ¨ç†ï¼ˆé€Ÿåº¦è¾ƒæ…¢ä½†æ— æ˜¾å­˜é™åˆ¶ï¼‰

### é£é™©4: è¾“å‡ºæ ¼å¼ä¸ç¨³å®š âš ï¸

**é£é™©**: æ¨¡å‹å¯èƒ½è¾“å‡ºæ ¼å¼é”™è¯¯çš„JSONæˆ–æ— æ•ˆçš„è½¦å‹å

**ç¼“è§£**:
- æ·»åŠ è¾“å‡ºéªŒè¯é€»è¾‘
- ä½¿ç”¨çº¦æŸè§£ç ï¼ˆconstrained decodingï¼‰
- å¤±è´¥æ—¶å›é€€åˆ°è§„åˆ™åŒ¹é…æˆ–äº‘ç«¯API

## 7. æ€§èƒ½å¯¹æ¯”é¢„æœŸ

| æŒ‡æ ‡ | äº‘ç«¯API | æœ¬åœ°æ¨¡å‹ | è¯´æ˜ |
|------|---------|----------|------|
| è½¦å‹å‡†ç¡®ç‡ | ~95% | ç›®æ ‡â‰¥95% | éœ€è¦éªŒè¯ |
| æ±¡æŸ“ç‰©å‡†ç¡®ç‡ | ~98% | ç›®æ ‡â‰¥98% | éœ€è¦éªŒè¯ |
| åˆ—åæ˜ å°„å‡†ç¡®ç‡ | ~90% | ç›®æ ‡â‰¥90% | éœ€è¦éªŒè¯ |
| æ¨ç†å»¶è¿Ÿ | 200-500ms | 50-200ms (GPU) | æœ¬åœ°æ›´å¿« |
| æˆæœ¬ | æŒ‰è°ƒç”¨è®¡è´¹ | ä¸€æ¬¡æ€§è®­ç»ƒæˆæœ¬ | é•¿æœŸæœ¬åœ°æ›´çœ |
| ç¦»çº¿å¯ç”¨ | âŒ | âœ… | æœ¬åœ°ä¼˜åŠ¿ |

## 8. ç»“è®º

### âœ… å¯ä»¥æ— ç¼é›†æˆ

é€šè¿‡åˆ›å»ºé€‚é…å±‚ï¼ˆ`LocalStandardizer`ï¼‰ï¼Œæœ¬åœ°æ¨¡å‹å¯ä»¥å®Œå…¨å…¼å®¹ç°æœ‰å·¥ä½œæµï¼Œæ— éœ€ä¿®æ”¹ä¸šåŠ¡é€»è¾‘ä»£ç ã€‚

### ğŸ“‹ éœ€è¦å®Œæˆçš„å·¥ä½œ

1. **åˆ›å»ºé€‚é…å™¨ç±»** (1-2å°æ—¶)
2. **ä¿®æ”¹é…ç½®å’Œåˆå§‹åŒ–** (1å°æ—¶)
3. **å®Œæˆæ¨¡å‹è®­ç»ƒ** (3-5å°æ—¶ï¼Œéœ€è¦GPU)
4. **é›†æˆæµ‹è¯•** (2-3å°æ—¶)
5. **æ€§èƒ½ä¼˜åŒ–** (å¯é€‰ï¼Œ1-2å°æ—¶)

**æ€»è®¡**: çº¦8-13å°æ—¶å·¥ä½œé‡

### ğŸ¯ æ¨èè¡ŒåŠ¨è®¡åˆ’

1. **ç«‹å³**: åˆ›å»º `local_client.py` é€‚é…å™¨ç±»
2. **è®­ç»ƒå®Œæˆå**: é›†æˆæµ‹è¯•
3. **éªŒè¯é€šè¿‡å**: é€æ­¥åˆ‡æ¢åˆ°æœ¬åœ°æ¨¡å‹
4. **ä¿ç•™å›é€€**: ä¿æŒäº‘ç«¯APIä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ

### ğŸ’¡ å…³é”®å»ºè®®

- ä½¿ç”¨é…ç½®å¼€å…³ï¼Œæ–¹ä¾¿åœ¨æœ¬åœ°å’Œäº‘ç«¯ä¹‹é—´åˆ‡æ¢
- æ·»åŠ è¯¦ç»†æ—¥å¿—ï¼Œä¾¿äºè°ƒè¯•å’Œæ€§èƒ½åˆ†æ
- å®ç°ç¼“å­˜æœºåˆ¶ï¼Œæå‡é‡å¤æŸ¥è¯¢æ€§èƒ½
- å®šæœŸæ”¶é›†é”™è¯¯æ¡ˆä¾‹ï¼ŒæŒç»­æ”¹è¿›æ¨¡å‹
