# æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹é›†æˆæŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•å°†æœ¬åœ°å¾®è°ƒçš„Qwen3-4Bæ¨¡å‹é›†æˆåˆ°emission_agentï¼Œæ›¿ä»£äº‘ç«¯APIè°ƒç”¨ã€‚

## ğŸ¯ æ¨¡å‹æ¶æ„

- **åŸºç¡€æ¨¡å‹**: Qwen/Qwen2.5-3B-Instruct
- **å¾®è°ƒæ–¹æ³•**: LoRA (Low-Rank Adaptation)
- **ä¸¤ä¸ªç‹¬ç«‹é€‚é…å™¨**:
  - `unified_lora`: è½¦å‹æ ‡å‡†åŒ– + æ±¡æŸ“ç‰©æ ‡å‡†åŒ–
  - `column_lora`: åˆ—åæ˜ å°„
- **ç­–ç•¥**: åŠ è½½ä¸€ä¸ªåŸºç¡€æ¨¡å‹ï¼ŒåŠ¨æ€åˆ‡æ¢ä¸åŒçš„LoRAé€‚é…å™¨

## ğŸ”§ éƒ¨ç½²æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆ1: ç›´æ¥åŠ è½½ï¼ˆæ¨èç”¨äºå¼€å‘/æµ‹è¯•ï¼‰

**ä¼˜ç‚¹**:
- ç®€å•ï¼Œæ— éœ€é¢å¤–æœåŠ¡
- é€‚åˆå•ç”¨æˆ·åœºæ™¯
- è°ƒè¯•æ–¹ä¾¿

**ç¼ºç‚¹**:
- æ¯æ¬¡è¯·æ±‚éƒ½éœ€è¦åŠ è½½æ¨¡å‹
- æ˜¾å­˜å ç”¨é«˜ï¼ˆ~6GBï¼‰
- å»¶è¿Ÿè¾ƒé«˜ï¼ˆé¦–æ¬¡åŠ è½½æ…¢ï¼‰

**é€‚ç”¨åœºæ™¯**: å¼€å‘æµ‹è¯•ã€å•ç”¨æˆ·ä½¿ç”¨

### æ–¹æ¡ˆ2: VLLMæœåŠ¡ï¼ˆæ¨èç”¨äºç”Ÿäº§ï¼‰

**ä¼˜ç‚¹**:
- é«˜æ€§èƒ½æ¨ç†ï¼ˆPagedAttentionï¼‰
- æ”¯æŒæ‰¹å¤„ç†
- æ˜¾å­˜ä¼˜åŒ–
- æ”¯æŒå¤šç”¨æˆ·å¹¶å‘

**ç¼ºç‚¹**:
- éœ€è¦é¢å¤–å¯åŠ¨æœåŠ¡
- é…ç½®ç¨å¤æ‚
- éœ€è¦WSL2ï¼ˆWindowsç”¨æˆ·ï¼‰

**é€‚ç”¨åœºæ™¯**: ç”Ÿäº§ç¯å¢ƒã€å¤šç”¨æˆ·ã€é«˜å¹¶å‘

## ğŸ“ é›†æˆæ­¥éª¤

### æ­¥éª¤1: ç¡®è®¤æ¨¡å‹è®­ç»ƒå®Œæˆ

æ£€æŸ¥æ¨¡å‹checkpointæ˜¯å¦å­˜åœ¨ï¼š

```bash
# æ£€æŸ¥unified_loraæ¨¡å‹
ls LOCAL_STANDARDIZER_MODEL/models/unified_lora/

# æ£€æŸ¥column_loraæ¨¡å‹
ls LOCAL_STANDARDIZER_MODEL/models/column_lora/
```

**å¦‚æœæ¨¡å‹ä¸å­˜åœ¨**ï¼Œéœ€è¦å…ˆè®­ç»ƒï¼š

```bash
cd LOCAL_STANDARDIZER_MODEL

# è®­ç»ƒunifiedæ¨¡å‹
python scripts/04_train_lora.py --config configs/unified_lora_config.yaml --model_type unified

# è®­ç»ƒcolumnæ¨¡å‹
python scripts/04_train_lora.py --config configs/column_lora_config.yaml --model_type column
```

**æ ¹æ®ä½ çš„æè¿°**ï¼Œåˆ—æ ‡å‡†åŒ–çš„æœ€ä½³æ¨¡å‹åœ¨ç¬¬200æ­¥ï¼ˆepoch 1.25ï¼‰ï¼Œåº”è¯¥åœ¨ï¼š
```
LOCAL_STANDARDIZER_MODEL/models/column_lora/checkpoint-200/
```

### æ­¥éª¤2: æ·»åŠ é…ç½®å¼€å…³

ç¼–è¾‘ `config.py`ï¼Œæ·»åŠ æœ¬åœ°æ¨¡å‹é…ç½®ï¼š

```python
@dataclass
class Config:
    def __post_init__(self):
        # ... ç°æœ‰é…ç½® ...

        # ============ æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹é…ç½® ============
        self.use_local_standardizer = os.getenv("USE_LOCAL_STANDARDIZER", "false").lower() == "true"

        self.local_standardizer_config = {
            "enabled": self.use_local_standardizer,
            "mode": os.getenv("LOCAL_STANDARDIZER_MODE", "direct"),  # "direct" or "vllm"
            "base_model": os.getenv("LOCAL_STANDARDIZER_BASE_MODEL", "Qwen/Qwen2.5-3B-Instruct"),
            "unified_lora": os.getenv("LOCAL_STANDARDIZER_UNIFIED_LORA", "./LOCAL_STANDARDIZER_MODEL/models/unified_lora/final"),
            "column_lora": os.getenv("LOCAL_STANDARDIZER_COLUMN_LORA", "./LOCAL_STANDARDIZER_MODEL/models/column_lora/checkpoint-200"),
            "device": os.getenv("LOCAL_STANDARDIZER_DEVICE", "cuda"),  # "cuda" or "cpu"
            "max_length": int(os.getenv("LOCAL_STANDARDIZER_MAX_LENGTH", "256")),
            "vllm_url": os.getenv("LOCAL_STANDARDIZER_VLLM_URL", "http://localhost:8001"),
        }
```

### æ­¥éª¤3: æ›´æ–° `.env` æ–‡ä»¶

æ·»åŠ æœ¬åœ°æ¨¡å‹é…ç½®ï¼š

```bash
# ============ æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹é…ç½® ============
# æ˜¯å¦ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆtrue/falseï¼‰
USE_LOCAL_STANDARDIZER=false

# æ¨¡å¼ï¼šdirectï¼ˆç›´æ¥åŠ è½½ï¼‰æˆ– vllmï¼ˆVLLMæœåŠ¡ï¼‰
LOCAL_STANDARDIZER_MODE=direct

# åŸºç¡€æ¨¡å‹è·¯å¾„
LOCAL_STANDARDIZER_BASE_MODEL=Qwen/Qwen2.5-3B-Instruct

# LoRAé€‚é…å™¨è·¯å¾„
LOCAL_STANDARDIZER_UNIFIED_LORA=./LOCAL_STANDARDIZER_MODEL/models/unified_lora/final
LOCAL_STANDARDIZER_COLUMN_LORA=./LOCAL_STANDARDIZER_MODEL/models/column_lora/checkpoint-200

# è®¾å¤‡ï¼šcuda æˆ– cpu
LOCAL_STANDARDIZER_DEVICE=cuda

# VLLMæœåŠ¡åœ°å€ï¼ˆä»…åœ¨mode=vllmæ—¶ä½¿ç”¨ï¼‰
LOCAL_STANDARDIZER_VLLM_URL=http://localhost:8001
```

### æ­¥éª¤4: åˆ›å»ºæœ¬åœ°æ¨¡å‹å®¢æˆ·ç«¯

åˆ›å»º `shared/standardizer/local_client.py`ï¼š

```python
import json
import logging
import torch
from typing import Optional, Dict, List
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import requests

logger = logging.getLogger(__name__)

class LocalStandardizerClient:
    """æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹å®¢æˆ·ç«¯"""

    def __init__(self, config: Dict):
        self.config = config
        self.mode = config.get("mode", "direct")

        if self.mode == "direct":
            self._init_direct_mode()
        elif self.mode == "vllm":
            self._init_vllm_mode()
        else:
            raise ValueError(f"Unknown mode: {self.mode}")

    def _init_direct_mode(self):
        """åˆå§‹åŒ–ç›´æ¥åŠ è½½æ¨¡å¼"""
        logger.info("åˆå§‹åŒ–æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹ï¼ˆç›´æ¥åŠ è½½æ¨¡å¼ï¼‰...")

        device = self.config.get("device", "cuda")
        base_model_path = self.config.get("base_model")

        # åŠ è½½tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(base_model_path)

        # åŠ è½½åŸºç¡€æ¨¡å‹
        self.base_model = AutoModelForCausalLM.from_pretrained(
            base_model_path,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            device_map=device
        )

        # åŠ è½½LoRAé€‚é…å™¨
        self.unified_lora_path = self.config.get("unified_lora")
        self.column_lora_path = self.config.get("column_lora")

        # å½“å‰åŠ è½½çš„é€‚é…å™¨
        self.current_adapter = None
        self.model = None

        logger.info("æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

    def _init_vllm_mode(self):
        """åˆå§‹åŒ–VLLMæ¨¡å¼"""
        logger.info("åˆå§‹åŒ–æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹ï¼ˆVLLMæ¨¡å¼ï¼‰...")
        self.vllm_url = self.config.get("vllm_url")
        logger.info(f"VLLMæœåŠ¡åœ°å€: {self.vllm_url}")

    def _switch_adapter(self, adapter_type: str):
        """åˆ‡æ¢LoRAé€‚é…å™¨"""
        if self.mode == "vllm":
            # VLLMæ¨¡å¼ä¸éœ€è¦åˆ‡æ¢é€‚é…å™¨
            return

        if self.current_adapter == adapter_type:
            return

        logger.info(f"åˆ‡æ¢LoRAé€‚é…å™¨: {adapter_type}")

        if adapter_type == "unified":
            lora_path = self.unified_lora_path
        elif adapter_type == "column":
            lora_path = self.column_lora_path
        else:
            raise ValueError(f"Unknown adapter type: {adapter_type}")

        # åŠ è½½LoRAé€‚é…å™¨
        self.model = PeftModel.from_pretrained(self.base_model, lora_path)
        self.current_adapter = adapter_type

    def _generate_direct(self, prompt: str) -> str:
        """ç›´æ¥ç”Ÿæˆï¼ˆéVLLMï¼‰"""
        messages = [
            {"role": "system", "content": "ä½ æ˜¯æ ‡å‡†åŒ–åŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ]

        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )

        inputs = self.tokenizer([text], return_tensors="pt").to(self.model.device)

        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=self.config.get("max_length", 256),
                temperature=0.1,
                do_sample=False
            )

        response = self.tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)
        return response.strip()

    def _generate_vllm(self, prompt: str, adapter: str) -> str:
        """é€šè¿‡VLLMç”Ÿæˆ"""
        response = requests.post(
            f"{self.vllm_url}/v1/completions",
            json={
                "model": adapter,  # "unified" or "column"
                "prompt": prompt,
                "max_tokens": self.config.get("max_length", 256),
                "temperature": 0.1
            }
        )
        response.raise_for_status()
        return response.json()["choices"][0]["text"].strip()

    def standardize_vehicle(self, input_text: str) -> str:
        """æ ‡å‡†åŒ–è½¦å‹"""
        self._switch_adapter("unified")
        prompt = f"[vehicle] {input_text}"

        if self.mode == "direct":
            return self._generate_direct(prompt)
        else:
            return self._generate_vllm(prompt, "unified")

    def standardize_pollutant(self, input_text: str) -> str:
        """æ ‡å‡†åŒ–æ±¡æŸ“ç‰©"""
        self._switch_adapter("unified")
        prompt = f"[pollutant] {input_text}"

        if self.mode == "direct":
            return self._generate_direct(prompt)
        else:
            return self._generate_vllm(prompt, "unified")

    def map_columns(self, columns: List[str], task_type: str) -> Dict[str, str]:
        """æ˜ å°„åˆ—å"""
        self._switch_adapter("column")

        # æ„å»ºprompt
        system_prompt = f"""ä½ æ˜¯åˆ—åæ˜ å°„åŠ©æ‰‹ã€‚åˆ†æExcelè¡¨æ ¼åˆ—åï¼Œå°†å…¶æ˜ å°„åˆ°æ ‡å‡†å­—æ®µã€‚

ä»»åŠ¡ç±»å‹: {task_type}

è¿”å›JSONæ ¼å¼çš„æ˜ å°„ï¼Œåªè¿”å›èƒ½è¯†åˆ«çš„åˆ—ã€‚"""

        prompt = json.dumps(columns, ensure_ascii=False)

        if self.mode == "direct":
            result = self._generate_direct(prompt)
        else:
            result = self._generate_vllm(prompt, "column")

        try:
            return json.loads(result)
        except json.JSONDecodeError:
            logger.error(f"JSONè§£æå¤±è´¥: {result}")
            return {}
```

### æ­¥éª¤5: ä¿®æ”¹ç°æœ‰Standardizer

ä¿®æ”¹ `shared/standardizer/vehicle.py` å’Œ `pollutant.py`ï¼Œæ·»åŠ æœ¬åœ°æ¨¡å‹æ”¯æŒï¼š

```python
# åœ¨ VehicleStandardizer.__new__ ä¸­æ·»åŠ 
def __new__(cls):
    if cls._instance is None:
        cls._instance = super().__new__(cls)
        config = get_config()

        # é€‰æ‹©ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿˜æ˜¯API
        if config.use_local_standardizer:
            from .local_client import LocalStandardizerClient
            cls._instance._local_client = LocalStandardizerClient(config.local_standardizer_config)
            cls._instance._use_local = True
        else:
            cls._instance._llm = get_llm("standardizer") if config.enable_llm_standardization else None
            cls._instance._use_local = False

        # ... å…¶ä»–åˆå§‹åŒ– ...
    return cls._instance

# ä¿®æ”¹ _llm_standardize æ–¹æ³•
def _llm_standardize(self, user_input: str) -> Optional[StandardizationResult]:
    if self._use_local:
        # ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        try:
            standard = self._local_client.standardize_vehicle(user_input)
            if standard in STANDARD_VEHICLE_TYPES:
                return StandardizationResult(user_input, standard, 0.95, "local_llm")
        except Exception as e:
            logger.error(f"æœ¬åœ°æ¨¡å‹æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return None
    else:
        # ä½¿ç”¨APIï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        # ...
```

## ğŸš€ å¯åŠ¨æ–¹å¼

### æ–¹å¼1: ç›´æ¥åŠ è½½æ¨¡å¼

```bash
# 1. ä¿®æ”¹ .env
USE_LOCAL_STANDARDIZER=true
LOCAL_STANDARDIZER_MODE=direct

# 2. é‡å¯æœåŠ¡å™¨
.\scripts\restart_server.ps1
```

### æ–¹å¼2: VLLMæ¨¡å¼ï¼ˆæ¨èï¼‰

#### Windowsç”¨æˆ·ï¼ˆä½¿ç”¨WSL2ï¼‰

```bash
# 1. åœ¨WSL2ä¸­å®‰è£…VLLM
wsl
conda create -n vllm python=3.10 -y
conda activate vllm
pip install vllm

# 2. å¯åŠ¨VLLMæœåŠ¡ï¼ˆunifiedæ¨¡å‹ï¼‰
vllm serve Qwen/Qwen2.5-3B-Instruct \
    --enable-lora \
    --lora-modules unified=/mnt/d/Agent_MCP/emission_agent/LOCAL_STANDARDIZER_MODEL/models/unified_lora/final \
    --lora-modules column=/mnt/d/Agent_MCP/emission_agent/LOCAL_STANDARDIZER_MODEL/models/column_lora/checkpoint-200 \
    --port 8001 \
    --gpu-memory-utilization 0.8

# 3. åœ¨Windowsä¸­ä¿®æ”¹ .env
USE_LOCAL_STANDARDIZER=true
LOCAL_STANDARDIZER_MODE=vllm
LOCAL_STANDARDIZER_VLLM_URL=http://localhost:8001

# 4. é‡å¯æœåŠ¡å™¨
.\scripts\restart_server.ps1
```

#### Linuxç”¨æˆ·

```bash
# 1. å®‰è£…VLLM
pip install vllm

# 2. å¯åŠ¨VLLMæœåŠ¡
vllm serve Qwen/Qwen2.5-3B-Instruct \
    --enable-lora \
    --lora-modules unified=./LOCAL_STANDARDIZER_MODEL/models/unified_lora/final \
    --lora-modules column=./LOCAL_STANDARDIZER_MODEL/models/column_lora/checkpoint-200 \
    --port 8001 \
    --gpu-memory-utilization 0.8

# 3. ä¿®æ”¹ .env
USE_LOCAL_STANDARDIZER=true
LOCAL_STANDARDIZER_MODE=vllm

# 4. é‡å¯æœåŠ¡å™¨
./scripts/restart_server.sh
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | APIæ¨¡å¼ | ç›´æ¥åŠ è½½ | VLLMæ¨¡å¼ |
|------|---------|----------|----------|
| é¦–æ¬¡å»¶è¿Ÿ | ~500ms | ~3000ms | ~100ms |
| åç»­å»¶è¿Ÿ | ~500ms | ~200ms | ~50ms |
| æ˜¾å­˜å ç”¨ | 0 | ~6GB | ~4GB |
| å¹¶å‘æ”¯æŒ | é«˜ | ä½ | é«˜ |
| æˆæœ¬ | æŒ‰è°ƒç”¨è®¡è´¹ | å…è´¹ | å…è´¹ |

## ğŸ” æµ‹è¯•éªŒè¯

```bash
# æµ‹è¯•æœ¬åœ°æ¨¡å‹
python -c "
from shared.standardizer.vehicle import get_vehicle_standardizer
std = get_vehicle_standardizer()
result = std.standardize('å°æ±½è½¦')
print(f'è¾“å…¥: å°æ±½è½¦')
print(f'æ ‡å‡†: {result.standard}')
print(f'æ–¹æ³•: {result.method}')
"
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹è·¯å¾„**: ç¡®ä¿checkpoint-200å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œä½¿ç”¨æœ€æ–°çš„checkpointæˆ–finalç›®å½•
2. **æ˜¾å­˜è¦æ±‚**: è‡³å°‘éœ€è¦6GBæ˜¾å­˜ï¼ˆç›´æ¥åŠ è½½ï¼‰æˆ–4GBï¼ˆVLLMï¼‰
3. **é¦–æ¬¡åŠ è½½**: ç¬¬ä¸€æ¬¡åŠ è½½æ¨¡å‹ä¼šä¸‹è½½åŸºç¡€æ¨¡å‹ï¼ˆ~6GBï¼‰ï¼Œéœ€è¦æ—¶é—´
4. **WSL2è·¯å¾„**: Windowsç”¨æˆ·ä½¿ç”¨VLLMæ—¶ï¼Œè·¯å¾„éœ€è¦è½¬æ¢ä¸ºWSL2æ ¼å¼ï¼ˆ/mnt/d/...ï¼‰

## ğŸ¯ æ¨èé…ç½®

- **å¼€å‘/æµ‹è¯•**: ä½¿ç”¨APIæ¨¡å¼ï¼ˆç®€å•å¿«é€Ÿï¼‰
- **ç”Ÿäº§ç¯å¢ƒï¼ˆå•ç”¨æˆ·ï¼‰**: ä½¿ç”¨ç›´æ¥åŠ è½½æ¨¡å¼
- **ç”Ÿäº§ç¯å¢ƒï¼ˆå¤šç”¨æˆ·ï¼‰**: ä½¿ç”¨VLLMæ¨¡å¼

## ğŸ“ åˆ‡æ¢å›APIæ¨¡å¼

å¦‚æœéœ€è¦åˆ‡æ¢å›APIæ¨¡å¼ï¼š

```bash
# ä¿®æ”¹ .env
USE_LOCAL_STANDARDIZER=false

# é‡å¯æœåŠ¡å™¨
.\scripts\restart_server.ps1
```
