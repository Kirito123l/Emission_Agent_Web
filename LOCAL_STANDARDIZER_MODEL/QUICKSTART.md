# å¿«é€Ÿå¼€å§‹æŒ‡å—

æœ¬æŒ‡å—å¸®åŠ©ä½ å¿«é€Ÿå¼€å§‹æœ¬åœ°æ ‡å‡†åŒ–æ¨¡å‹çš„è®­ç»ƒå’Œä½¿ç”¨ã€‚

## å‰ç½®æ¡ä»¶

### ç¡¬ä»¶è¦æ±‚
- **GPU**: NVIDIA GPU with â‰¥16GB VRAM (æ¨è RTX 3090/4090 æˆ– A100)
- **å†…å­˜**: â‰¥32GB RAM
- **å­˜å‚¨**: â‰¥20GB å¯ç”¨ç©ºé—´

### è½¯ä»¶è¦æ±‚
- Python 3.8+
- CUDA 11.8+ (for GPU support)
- Git

## å®‰è£…æ­¥éª¤

### 1. å®‰è£…ä¾èµ–

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd D:/Agent_MCP/emission_agent/LOCAL_STANDARDIZER_MODEL

# å®‰è£… PyTorch (æ ¹æ®ä½ çš„ CUDA ç‰ˆæœ¬é€‰æ‹©)
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# å®‰è£…å…¶ä»–ä¾èµ–
pip install transformers peft datasets accelerate pyyaml tqdm bitsandbytes
```

### 2. éªŒè¯å®‰è£…

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
```

åº”è¯¥è¾“å‡º:
```
PyTorch: 2.x.x
CUDA available: True
```

## æ•°æ®å‡†å¤‡ï¼ˆå·²å®Œæˆï¼‰

æ•°æ®å·²ç»å‡†å¤‡å¥½ï¼Œä½äº `data/final/` ç›®å½•ï¼š
- âœ… ç»Ÿä¸€æ¨¡å‹: 5,121 æ¡æ•°æ®
- âœ… åˆ—åæ˜ å°„: 1,000 æ¡æ•°æ®

å¦‚éœ€é‡æ–°ç”Ÿæˆæ•°æ®:
```bash
python scripts/01_create_seed_data.py
python scripts/02_augment_data.py
python scripts/03_prepare_training_data.py
python scripts/validate_data.py
```

## æ¨¡å‹è®­ç»ƒ

### è®­ç»ƒç»Ÿä¸€æ¨¡å‹ï¼ˆè½¦å‹ + æ±¡æŸ“ç‰©æ ‡å‡†åŒ–ï¼‰

```bash
python scripts/04_train_lora.py \
    --config configs/unified_lora_config.yaml \
    --model_type unified
```

**è®­ç»ƒæ—¶é—´**: çº¦ 2-3 å°æ—¶ (RTX 3090)

**è¾“å‡º**: `models/unified_lora/final/`

### è®­ç»ƒåˆ—åæ˜ å°„æ¨¡å‹

```bash
python scripts/04_train_lora.py \
    --config configs/column_lora_config.yaml \
    --model_type column
```

**è®­ç»ƒæ—¶é—´**: çº¦ 1-2 å°æ—¶ (RTX 3090)

**è¾“å‡º**: `models/column_lora/final/`

## æ¨¡å‹è¯„ä¼°

### è¯„ä¼°ç»Ÿä¸€æ¨¡å‹

```bash
python scripts/06_evaluate.py \
    --model_type unified \
    --base_model Qwen/Qwen2.5-3B-Instruct \
    --lora_path models/unified_lora/final
```

**ç›®æ ‡å‡†ç¡®ç‡**:
- è½¦å‹æ ‡å‡†åŒ–: â‰¥95%
- æ±¡æŸ“ç‰©æ ‡å‡†åŒ–: â‰¥98%

### è¯„ä¼°åˆ—åæ˜ å°„æ¨¡å‹

```bash
python scripts/06_evaluate.py \
    --model_type column \
    --base_model Qwen/Qwen2.5-3B-Instruct \
    --lora_path models/column_lora/final
```

**ç›®æ ‡å‡†ç¡®ç‡**:
- å®Œå…¨åŒ¹é…: â‰¥90%

## å¿«é€Ÿæµ‹è¯•

è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥å¿«é€Ÿæµ‹è¯•æ¨¡å‹:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# åŠ è½½æ¨¡å‹
base_model = "Qwen/Qwen2.5-3B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(base_model, trust_remote_code=True, device_map="auto")
model = PeftModel.from_pretrained(model, "models/unified_lora/final")

# æµ‹è¯•è½¦å‹æ ‡å‡†åŒ–
messages = [
    {"role": "system", "content": "ä½ æ˜¯æ ‡å‡†åŒ–åŠ©æ‰‹..."},
    {"role": "user", "content": "[vehicle] å¤§è´§è½¦"}
]

text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
inputs = tokenizer(text, return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=32)
response = tokenizer.decode(outputs[0][inputs["input_ids"].shape[1]:], skip_special_tokens=True)

print(f"è¾“å…¥: å¤§è´§è½¦")
print(f"è¾“å‡º: {response}")  # åº”è¯¥è¾“å‡º: Combination Long-haul Truck
```

## å¸¸è§é—®é¢˜

### Q: æ˜¾å­˜ä¸è¶³ (OOM)

**è§£å†³æ–¹æ¡ˆ**:
1. å‡å°æ‰¹æ¬¡å¤§å°: åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® `per_device_train_batch_size: 2`
2. ä½¿ç”¨ 4bit é‡åŒ– (QLoRA)
3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (å¦‚ Qwen2.5-1.5B)

### Q: è®­ç»ƒé€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®ä¿ä½¿ç”¨ GPU: `torch.cuda.is_available()` åº”è¿”å› True
2. å‡å°‘ `logging_steps` å’Œ `eval_steps`
3. ä½¿ç”¨ Flash Attention (éœ€è¦ A100/H100)

### Q: å‡†ç¡®ç‡ä¸è¾¾æ ‡

**è§£å†³æ–¹æ¡ˆ**:
1. å¢åŠ è®­ç»ƒè½®æ•°
2. è°ƒæ•´å­¦ä¹ ç‡
3. å¢å¤§ LoRA rank
4. å¢åŠ è®­ç»ƒæ•°æ®

## ä¸‹ä¸€æ­¥

è®­ç»ƒå®Œæˆå:
1. è¯„ä¼°æ¨¡å‹æ€§èƒ½
2. é›†æˆåˆ° emission_agent é¡¹ç›®
3. è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•
4. æ€§èƒ½å¯¹æ¯”ï¼ˆæœ¬åœ° vs äº‘ç«¯ APIï¼‰

## è·å–å¸®åŠ©

- æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: `README.md`
- æŸ¥çœ‹è„šæœ¬è¯´æ˜: `scripts/README.md`
- æŸ¥çœ‹å®Œæˆæ€»ç»“: `SUMMARY.md`

## é¡¹ç›®ç»“æ„

```
LOCAL_STANDARDIZER_MODEL/
â”œâ”€â”€ README.md              # è¯¦ç»†å¼€å‘æ–‡æ¡£
â”œâ”€â”€ PROMPT.md              # ä»»åŠ¡è¯´æ˜
â”œâ”€â”€ SUMMARY.md             # å®Œæˆæ€»ç»“
â”œâ”€â”€ QUICKSTART.md          # æœ¬æ–‡æ¡£
â”œâ”€â”€ data/                  # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ raw/              # ç§å­æ•°æ®
â”‚   â”œâ”€â”€ augmented/        # å¢å¼ºæ•°æ®
â”‚   â””â”€â”€ final/            # è®­ç»ƒæ•°æ® âœ“
â”œâ”€â”€ scripts/              # è„šæœ¬ç›®å½• âœ“
â”œâ”€â”€ configs/              # é…ç½®æ–‡ä»¶ âœ“
â”œâ”€â”€ models/               # æ¨¡å‹è¾“å‡º
â”‚   â”œâ”€â”€ unified_lora/
â”‚   â””â”€â”€ column_lora/
â””â”€â”€ tests/                # æµ‹è¯•ç›®å½•
```

## æ—¶é—´ä¼°ç®—

| ä»»åŠ¡ | æ—¶é—´ (RTX 3090) |
|------|-----------------|
| æ•°æ®å‡†å¤‡ | âœ… å·²å®Œæˆ |
| è®­ç»ƒç»Ÿä¸€æ¨¡å‹ | 2-3 å°æ—¶ |
| è®­ç»ƒåˆ—åæ˜ å°„æ¨¡å‹ | 1-2 å°æ—¶ |
| æ¨¡å‹è¯„ä¼° | 10-20 åˆ†é’Ÿ |
| **æ€»è®¡** | **3-5 å°æ—¶** |

å¼€å§‹è®­ç»ƒå§ï¼ğŸš€
